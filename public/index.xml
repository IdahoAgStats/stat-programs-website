<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Idaho Ag Stats</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Idaho Ag Stats</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Copyright @ 2021 by the [University of Idaho Statistical Programs](https://www.uidaho.edu/cals/statistical-programs). Built with [WowChemy](https://wowchemy.com/).</copyright><lastBuildDate>Wed, 17 Nov 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/icon_hu3b3c4a2d8f23d5f02a77bc3c14c75958_2167_512x512_fill_lanczos_center_2.png</url>
      <title>Idaho Ag Stats</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Computational Set-up</title>
      <link>/workshops/spatial-workshop/prep-work/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/workshops/spatial-workshop/prep-work/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fab fa-r-project  pr-1 fa-fw&#34;&gt;&lt;/i&gt; Here are instructions for how check your R installation and install packages needed for the workshop.&lt;/p&gt;
&lt;h3 id=&#34;check-software-versions&#34;&gt;Check software versions&lt;/h3&gt;
&lt;p&gt;Open R and run this code to check what version of R your system is running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;R.Version()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the version printed is not 4.0 or newer, please &lt;a href=&#34;https://cran.r-project.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;upgrade R&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This step is not required if you do not use RStudio.&lt;/em&gt; Open RStudio and run this code to check what version of RStudio is installed on your system:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rstudioapi::versionInfo()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the version printed is not 1.4 or newer, please &lt;a href=&#34;https://www.rstudio.com/products/rstudio/download/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;upgrade Rstudio&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;install-workshop-packages&#34;&gt;Install workshop packages&lt;/h3&gt;
&lt;p&gt;Open R and run this script:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package_list &amp;lt;- c(&amp;quot;dplyr&amp;quot;, &amp;quot;tidyr&amp;quot;, &amp;quot;purrr&amp;quot;,       # for standard data manipulation
                  &amp;quot;ggplot2&amp;quot;, &amp;quot;desplot&amp;quot;,            # for plotting
                  &amp;quot;nlme&amp;quot;, &amp;quot;lme4&amp;quot;, &amp;quot;emmeans&amp;quot;,       # for linear modelling
                  &amp;quot;SpATS&amp;quot;,                         # for fitting splines
                  &amp;quot;sp&amp;quot;, &amp;quot;spdep&amp;quot;, &amp;quot;gstat&amp;quot;, &amp;quot;spaMM&amp;quot;, &amp;quot;sf&amp;quot;)    # for spatial modelling

install.packages(package_list)
sapply(package_list, require, character.only = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;div&gt;
    Please note that the spatial packages may take awhile to install, and you may run into problems with the installation. Please attempt installation &lt;em&gt;in advance&lt;/em&gt; of the workshop. The packages have all been successfully installed if after the &lt;code&gt;sapply(package_list, require, character.only = TRUE)&lt;/code&gt; is run, the R output is &amp;ldquo;TRUE&amp;rdquo; for each package. If you have problems installing and/or loading any of these packages that you are not able to resolve, contact us so we can help you, preferably &lt;em&gt;before&lt;/em&gt; the workshop.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;library-information&#34;&gt;Library Information&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;package&lt;/th&gt;
&lt;th&gt;usage&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://dplyr.tidyverse.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;dplyr&lt;/a&gt;, &lt;a href=&#34;https://tidyr.tidyverse.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tidyr&lt;/a&gt;,&lt;/td&gt;
&lt;td&gt;standard data manipulation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://purrr.tidyverse.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;purrr&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;for repeat functions&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=nlme&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nlme&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;mixed linear models with options for spatial covariates&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=lme4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;lme4&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;mixed linear models with crossed random effects&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://ggplot2-book.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ggplot&lt;/a&gt;, &lt;a href=&#34;http://kwstat.github.io/desplot/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;desplot&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;standard plotting packge and extension for plotting block outlines&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=SpATS&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SpATS&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;spline-fitting&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=sp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;preparation of spatial objects&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://r-spatial.github.io/spdep/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;spdep&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Moran&amp;rsquo;s I test&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=gstat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gstat&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;for fitting empirical variogram&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;spaMM&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;fits Matern covariances structure for mixed linear models&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/rvlenth/emmeans&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;emmeans&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;extracts marginal means from linear model objects&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Computational Set-up</title>
      <link>/draft-workshops/spatial_workshop_new/prep-work/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/draft-workshops/spatial_workshop_new/prep-work/</guid>
      <description>&lt;p&gt;Here are instructions for how check your R installation and install packages needed for the workshop.&lt;/p&gt;
&lt;h3 id=&#34;check-software-versions&#34;&gt;Check software versions&lt;/h3&gt;
&lt;p&gt;Open R and run this code to check what version of R your system is running:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;R.Version()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the version printed is not 4.0 or newer, please &lt;a href=&#34;https://cran.r-project.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;upgrade R&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This step is not required if you do not use RStudio.&lt;/em&gt; Open RStudio and run this code to check what version of RStudio is installed on your system:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rstudioapi::versionInfo()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the version printed is not 1.4 or newer, please &lt;a href=&#34;https://www.rstudio.com/products/rstudio/download/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;upgrade Rstudio&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;install-workshop-packages&#34;&gt;Install workshop packages&lt;/h3&gt;
&lt;p&gt;Open R and run this script:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;package_list &amp;lt;- c(&amp;quot;dplyr&amp;quot;, &amp;quot;tidyr&amp;quot;, &amp;quot;purrr&amp;quot;,       # for standard data manipulation
                  &amp;quot;ggplot2&amp;quot;, &amp;quot;desplot&amp;quot;,            # for plotting
                  &amp;quot;nlme&amp;quot;, &amp;quot;lme4&amp;quot;, &amp;quot;emmeans&amp;quot;,       # for linear modelling
                  &amp;quot;SpATS&amp;quot;,                         # for fitting splines
                  &amp;quot;sp&amp;quot;, &amp;quot;spdep&amp;quot;, &amp;quot;gstat&amp;quot;, &amp;quot;sf&amp;quot;)    # for spatial modelling

install.packages(package_list)
sapply(package_list, require, character.only = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please note that the spatial packages may take awhile to install, and you may run into problems with the installation. Please install these in advance of the workshop. If you have problems installing and/or loading any of these packages that you are not able to resolve, contact us so we can help you, preferably &lt;em&gt;before&lt;/em&gt; the workshop.&lt;/p&gt;
&lt;h3 id=&#34;download-files-for-workshop&#34;&gt;Download files for workshop&lt;/h3&gt;
&lt;p&gt;The following files are used in the workshop:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/stroup_nin_wheat.csv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nebraska Interstate Nursery&lt;/a&gt;, a wheat variety trial arranged in a randomised complete block design with 4 blocks. This data set was first described by W. Stroup (2004) and has been used extensively for spatial analysis.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/AB19F5_LIND.csv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lind&lt;/a&gt;, a winter wheat variety trial from Washington using an augmented design. This data set was kindly donated by &lt;a href=&#34;https://www.ars.usda.gov/pacific-west-area/pullman-wa/whgq/people/kimberly-garland-campbell/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kimberly Garland Campbell&lt;/a&gt; of the USDA-ARS.&lt;/p&gt;
&lt;p&gt;Please download these in advance so you can run the R and/or SAS scripts in the workshop.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why Care about Spatial Variation?</title>
      <link>/workshops/spatial-workshop/why-spatial/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/workshops/spatial-workshop/why-spatial/</guid>
      <description>&lt;h4 id=&#34;agricultural-field-trials&#34;&gt;Agricultural field trials&lt;/h4&gt;














&lt;figure  id=&#34;figure-university-research-farm&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;University Research Farm&#34; srcset=&#34;
               /media/Parker_farm_hu5b749468aa26ddd0a9f36916aa2c4955_1521271_9da15a781bb8c2a2cbaf502640dda605.png 400w,
               /media/Parker_farm_hu5b749468aa26ddd0a9f36916aa2c4955_1521271_50ad91b5571235d1fb26c5f8052cd681.png 760w,
               /media/Parker_farm_hu5b749468aa26ddd0a9f36916aa2c4955_1521271_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/Parker_farm_hu5b749468aa26ddd0a9f36916aa2c4955_1521271_9da15a781bb8c2a2cbaf502640dda605.png&#34;
               width=&#34;760&#34;
               height=&#34;423&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      University Research Farm
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;The goal of many agricultural field trials is to provide information about crop response to a set a treatments such as soil treatments, disease pressure or crop genetic variation.&lt;/p&gt;














&lt;figure  id=&#34;figure-vartest&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/variety_testing_hu91f40b680ee6584d31c566c5259b98ab_3192801_3666819c024fb8498a6fb7ebc2a81ec6.JPG 400w,
               /media/variety_testing_hu91f40b680ee6584d31c566c5259b98ab_3192801_734f15ebc4d60affaea8fdeac1dccabf.JPG 760w,
               /media/variety_testing_hu91f40b680ee6584d31c566c5259b98ab_3192801_1200x1200_fit_q75_lanczos.JPG 1200w&#34;
               src=&#34;/media/variety_testing_hu91f40b680ee6584d31c566c5259b98ab_3192801_3666819c024fb8498a6fb7ebc2a81ec6.JPG&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h4 id=&#34;field-variation&#34;&gt;Field variation&lt;/h4&gt;
&lt;p&gt;Agricultural field trials often employ popular experimental designs such as randomized complete block design to account for environmental heterogeneity. However, those techniques are quite often inadequate to fully account for spatial heterogeneity that arises due to field position, soil conditions, disease, wildlife impacts and more.&lt;/p&gt;
&lt;p&gt;Here is the a map of a wheat variety trial conducted in Idaho with a chloropleth map indicating plot yield. Each square represents a plot.&lt;/p&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/Kimberly2013_hufcda326c681836e362ae8f277219c861_133784_6783117ac31579be4ba79158430a5c8e.png 400w,
               /media/Kimberly2013_hufcda326c681836e362ae8f277219c861_133784_0796f24bf395714b76e0185fb6d1fb6c.png 760w,
               /media/Kimberly2013_hufcda326c681836e362ae8f277219c861_133784_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/Kimberly2013_hufcda326c681836e362ae8f277219c861_133784_6783117ac31579be4ba79158430a5c8e.png&#34;
               width=&#34;760&#34;
               height=&#34;456&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;h4 id=&#34;blocking-in-a-field-trial&#34;&gt;Blocking in a field trial&lt;/h4&gt;
&lt;p&gt;Block is not always sufficient to account for spatial variation. Here is the same Idaho variety trial with block information overlaid:&lt;/p&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/Kimberly2013_blocking_hufcda326c681836e362ae8f277219c861_135684_c910abd22cf81daeeb4bd452fa2368f0.png 400w,
               /media/Kimberly2013_blocking_hufcda326c681836e362ae8f277219c861_135684_7f89ae5d4011a3c958aefee39855e94c.png 760w,
               /media/Kimberly2013_blocking_hufcda326c681836e362ae8f277219c861_135684_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/Kimberly2013_blocking_hufcda326c681836e362ae8f277219c861_135684_c910abd22cf81daeeb4bd452fa2368f0.png&#34;
               width=&#34;760&#34;
               height=&#34;456&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;The block arrangement is clearly not aligning with the field variation.&lt;/p&gt;
&lt;h4 id=&#34;when-spatial-variation-is-not-fully-accounted-for&#34;&gt;When Spatial Variation is not Fully Accounted For&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The treatment rankings can be wrong. Here is a plot of the cultivar ranks for yield from the Idaho variety trial when analysed with a standard linear mixed model and the same model augmented with spatial covariates.&lt;/li&gt;
&lt;/ul&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/Kimberly2013_ranks_huc1b2eb09556372696e77ae4f8ee42364_283302_f8fe488cc657eea6d907333649c08f07.png 400w,
               /media/Kimberly2013_ranks_huc1b2eb09556372696e77ae4f8ee42364_283302_06d53b914bc401e020b8db69b917798b.png 760w,
               /media/Kimberly2013_ranks_huc1b2eb09556372696e77ae4f8ee42364_283302_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/Kimberly2013_ranks_huc1b2eb09556372696e77ae4f8ee42364_283302_f8fe488cc657eea6d907333649c08f07.png&#34;
               width=&#34;760&#34;
               height=&#34;456&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;Error terms are often correlated with each other, invalidating the downstream analysis&lt;/li&gt;
&lt;/ul&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/resids_hu3126d5daa04687742bde609f4b9a11d2_46731_6aab43ce9784e2d07419f7d7b54c493f.png 400w,
               /media/resids_hu3126d5daa04687742bde609f4b9a11d2_46731_f438523eba3ff36d5d4a6460b5f74951.png 760w,
               /media/resids_hu3126d5daa04687742bde609f4b9a11d2_46731_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/resids_hu3126d5daa04687742bde609f4b9a11d2_46731_6aab43ce9784e2d07419f7d7b54c493f.png&#34;
               width=&#34;720&#34;
               height=&#34;432&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;high error/low precision/wide confidence intervals/low experimental power&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;blocking-versus-spatial-statistics&#34;&gt;Blocking versus spatial statistics&lt;/h4&gt;














&lt;figure  id=&#34;figure-another-distracted-boyfriend-meme&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;another distracted boyfriend meme!&#34; srcset=&#34;
               /media/boyfriend_meme_hu0bb4fc25b36bd5709c7ac9216fac1bd5_110631_f6b16f5fd9fe04db808a4129de3e15dd.jpg 400w,
               /media/boyfriend_meme_hu0bb4fc25b36bd5709c7ac9216fac1bd5_110631_6e44bc1d6558553d9eb1bd59a7a01470.jpg 760w,
               /media/boyfriend_meme_hu0bb4fc25b36bd5709c7ac9216fac1bd5_110631_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;/media/boyfriend_meme_hu0bb4fc25b36bd5709c7ac9216fac1bd5_110631_f6b16f5fd9fe04db808a4129de3e15dd.jpg&#34;
               width=&#34;750&#34;
               height=&#34;500&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      another distracted boyfriend meme!
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Researchers do not have to abandon blocking when incorporating spatial covariates into analysis of a field trial. In fact, using blocking or other experimental designs combined with spatial modelling has been shown improve the quality of the final estimates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Diagnosing Spatial Autocorrelation</title>
      <link>/workshops/spatial-workshop/diagnosis/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/workshops/spatial-workshop/diagnosis/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This workshop is concerned with &lt;strong&gt;areal&lt;/strong&gt; data, that is, data that occurs in discrete units (plots, in most cases). This attribute of trial data impacts many aspects of spatial analysis
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Spatial autocorrelation refers to similarity between points that are close to one another.  That correlation is expected to decline with distance. Note that is different from experiment-wide gradients, such as a salinity gradient or position on a slope.&lt;/p&gt;
&lt;h3 id=&#34;plotting&#34;&gt;Plotting&lt;/h3&gt;
&lt;p&gt;One of the easiest ways to diagnose spatial autocorrelation is by plotting data by its spatial position and using a heat map to indicate values of a response variable.&lt;/p&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/SOS_2017_hu798d915d3ca3a6f805e7339a3e2de09d_966931_94317cb58645d718ffcb5c4e584d1ee9.png 400w,
               /media/SOS_2017_hu798d915d3ca3a6f805e7339a3e2de09d_966931_328483d39fcc1fbc7f4572fb76a41bfe.png 760w,
               /media/SOS_2017_hu798d915d3ca3a6f805e7339a3e2de09d_966931_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/SOS_2017_hu798d915d3ca3a6f805e7339a3e2de09d_966931_94317cb58645d718ffcb5c4e584d1ee9.png&#34;
               width=&#34;760&#34;
               height=&#34;434&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;While there is always ambiguity associated with using plots for decision making, early exploration of these plots can be helpful in understanding the extent of spatial correlation.&lt;/p&gt;
&lt;h3 id=&#34;morans-i&#34;&gt;Moran&amp;rsquo;s I&lt;/h3&gt;
&lt;p&gt;Moran&amp;rsquo;s I, sometimes called &amp;ldquo;Global Moran&amp;rsquo;s I&amp;rdquo; can be used for conducting a hypothesis test on whether there is correlation between spatial units located adjacent to one another.&lt;/p&gt;
&lt;p&gt;$$ I = \frac{N}{W}\frac{\sum_i \sum_j w_{ij} (x_i - \bar{x})(x_j - \bar{x})}{\sum_i(x_i - \bar{x})^2}
\qquad i \neq j$$&lt;/p&gt;
&lt;p&gt;Where N is total number of spatial locations indexed by $i$ and $j$, x is the variable of interest, $w_{ij}$ are a spatial weights between each $i$ and $j$, and W is the sum of all weights.&lt;/p&gt;
&lt;p&gt;The expected values of Moran&amp;rsquo;s I is $-1/(N-1)$. Values greater than the expected value indicate positive spatial correlation (areas close to each other are similar), while values less than that indicate dissimilarity as spatial distance between points decreases.&lt;/p&gt;
&lt;h3 id=&#34;defining-neighbors&#34;&gt;Defining Neighbors&lt;/h3&gt;
&lt;p&gt;There are &lt;a href=&#34;https://r-spatial.github.io/spdep/reference/nb2listw.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;several options&lt;/a&gt; for defining adjacent neighbors and how to weight each neighbor&amp;rsquo;s influence. The two common configurations for defining neighbors are the rook and queen configurations. These are exactly what their chess analogy suggests: &amp;ldquo;rook&amp;rdquo; defines neighbors in an row/column fashion, while &amp;ldquo;queen&amp;rdquo; defines neighbors in a row/column configuration an also neighbors located diagonally at a 45 degree angle from the row/column neighbors. Determining this can be &lt;a href=&#34;https://r-spatial.github.io/spdep/articles/nb.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;complicated&lt;/a&gt; when working with irregularly-placed data (e.g. counties), but is quite unambiguous for lattice data common in planned field experiments.&lt;/p&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/neighbors_hufe5a74dfc647783bb8cb2ac3e6bbaf7e_14102_5b5e7b00e31159d69d33479b3238f7fb.png 400w,
               /media/neighbors_hufe5a74dfc647783bb8cb2ac3e6bbaf7e_14102_f423b76df8f3d3b2b6760c2dddf4daf4.png 760w,
               /media/neighbors_hufe5a74dfc647783bb8cb2ac3e6bbaf7e_14102_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/neighbors_hufe5a74dfc647783bb8cb2ac3e6bbaf7e_14102_5b5e7b00e31159d69d33479b3238f7fb.png&#34;
               width=&#34;760&#34;
               height=&#34;543&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;Setting the values for weights is a function of both how neighbors are defined and their proximity to the unit of interest. However, a very popular method is to define each neighbor as equal fractions that sum to one, e.g. in rook formation, each neighbor is weighted 0.25 (assuming an interior plot with 4 neighbors).&lt;/p&gt;
&lt;h3 id=&#34;empirical-variogram&#34;&gt;Empirical variogram&lt;/h3&gt;
&lt;p&gt;This is one of the most useful methods of determining the extent of spatial variability and will be covered in the following sections.&lt;/p&gt;
&lt;h3 id=&#34;code-for-this-section&#34;&gt;Code for this section&lt;/h3&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;R&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;# load libraries
library(dplyr); library(ggplot2); library(desplot); 
library(spdep); library(sf); library(nlme)

# read in data and prepare it
Nin &amp;lt;- read.csv(&amp;quot;stroup_nin_wheat.csv&amp;quot;) %&amp;gt;% 
  mutate(col.width = col * 1.2, row.length = row * 4.3) %&amp;gt;% 
  mutate(name = case_when(is.na(as.character(rep)) ~ NA_character_, 
                          TRUE ~ as.character(gen))) %&amp;gt;% 
  arrange(col, row)

Nin_na &amp;lt;- filter(Nin, !is.na(rep))

# make exploratory plot
ggplot(Nin, aes(x = row, y = col)) +
  geom_tile(aes(fill = yield), col = &amp;quot;white&amp;quot;) +
  geom_tileborder(aes(group = 1, grp = rep), lwd = 1.2) +
  labs(x = &amp;quot;row&amp;quot;, y = &amp;quot;column&amp;quot;, title = &amp;quot;field plot layout&amp;quot;) + 
  theme_classic() +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12))

## conduct moran&#39;s I test ##

# set neighbors with convenience function for grids
xy_rook &amp;lt;- cell2nb(nrow = max(Nin$row), ncol = max(Nin$col), 
  type=&amp;quot;rook&amp;quot;, torus = FALSE, legacy = FALSE)  

# run linear mixed model and extract residuals
nin.lme &amp;lt;- lme(fixed = yield ~ gen, random = ~1|rep,
              data = Nin, na.action = na.exclude)
resid_lme &amp;lt;- residuals(nin.lme)
names(resid_lme) &amp;lt;- Nin$plot

# two version of the Moran&#39;s I test: 
moran.test(resid_lme, nb2listw(xy_rook), na.action = na.exclude)
moran.mc(resid_lme, nb2listw(xy_rook), 999, na.action = na.exclude)
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;SAS&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;# read in data
proc format;
  invalue has_NA
  &#39;NA&#39; = .;
;

filename NIN url &amp;quot;https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/stroup_nin_wheat.csv&amp;quot;;

data alliance;
    infile NIN firstobs=2 delimiter=&#39;,&#39;;
    informat yield has_NA.;
    input entry $   rep $   yield   col row;
    Row  = 4.3*Row;
    Col = 1.2*Col;
    if yield=. then delete;
run;

# heatmap
proc sgplot data=alliance;
    HEATMAPPARM y=Row x=Col COLORRESPONSE=yield/ colormodel=(blue yellow green); 
run;

# linear mixed model
proc mixed data=alliance;
   class Rep Entry;
   model Yield = Entry / outp=residuals;
   random Rep;
run;

# Moran&#39;s I
proc variogram data=residuals plots(only)=moran ;
   compute lagd=1.2 maxlag=30 novariogram autocorr(assum=nor) ;
   coordinates xc=row yc=col;
   var resid;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
</description>
    </item>
    
    <item>
      <title>Python basics</title>
      <link>/draft-workshops/example/python/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>/draft-workshops/example/python/</guid>
      <description>&lt;p&gt;Build a foundation in Python.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/rfscVS0vtbw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;What is the difference between lists and tuples?&lt;/summary&gt;
  &lt;p&gt;&lt;p&gt;Lists&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lists are mutable - they can be changed&lt;/li&gt;
&lt;li&gt;Slower than tuples&lt;/li&gt;
&lt;li&gt;Syntax: &lt;code&gt;a_list = [1, 2.0, &#39;Hello world&#39;]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tuples&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tuples are immutable - they can&amp;rsquo;t be changed&lt;/li&gt;
&lt;li&gt;Tuples are faster than lists&lt;/li&gt;
&lt;li&gt;Syntax: &lt;code&gt;a_tuple = (1, 2.0, &#39;Hello world&#39;)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Is Python case-sensitive?&lt;/summary&gt;
  &lt;p&gt;Yes&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Empirical Variograms</title>
      <link>/workshops/spatial-workshop/variograms/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/workshops/spatial-workshop/variograms/</guid>
      <description>&lt;p&gt;The empirical variogram is a visual tool for quantifying spatial covariance. It uses semivariance ($\gamma$), which is a measure of covariance between points or units ($i$ and $j$) as a function of distance ($h$):&lt;/p&gt;
&lt;p&gt;$$\gamma(h) = \frac{1}{2|N(h)|}\sum_{N(h)}(x_i - x_j)^2$$&lt;/p&gt;
&lt;p&gt;Semivariances are binned for distance intervals. The average values for semivariance and distance interval can be fit to mathematical models designed to explain how semivariance changes over distance.&lt;/p&gt;
&lt;p&gt;Three important concepts of an empirical variogram are &lt;em&gt;nugget&lt;/em&gt;, &lt;em&gt;sill&lt;/em&gt; and  &lt;em&gt;range&lt;/em&gt;&lt;/p&gt;














&lt;figure  id=&#34;figure-example-empirical-variogram&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Example Empirical Variogram&#34; srcset=&#34;
               /media/Sadoti2014_spherical_huf033197c365a34c0f3cd93f8cc2a46a3_30850_84c00fa9c50ea6a6c12ad9bfe7b7fc54.jpg 400w,
               /media/Sadoti2014_spherical_huf033197c365a34c0f3cd93f8cc2a46a3_30850_264947b8bbb5022511399aab59b72492.jpg 760w,
               /media/Sadoti2014_spherical_huf033197c365a34c0f3cd93f8cc2a46a3_30850_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;/media/Sadoti2014_spherical_huf033197c365a34c0f3cd93f8cc2a46a3_30850_84c00fa9c50ea6a6c12ad9bfe7b7fc54.jpg&#34;
               width=&#34;640&#34;
               height=&#34;434&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Example Empirical Variogram
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;range = distance up to which is there is spatial correlation&lt;/li&gt;
&lt;li&gt;sill = uncorrelated variance of the variable of interest&lt;/li&gt;
&lt;li&gt;nugget = measurement error, or short-distance spatial variance and other unaccounted for variance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2 other concepts:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;partial sill = sill - nugget&lt;/li&gt;
&lt;li&gt;nugget effect = the nugget/sill ratio, interpreted opposite of $r^2$ (the closer it is to 1, the less the amount of spatial autocorrelation)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;correlated-error-models&#34;&gt;Correlated Error Models&lt;/h3&gt;
&lt;p&gt;Many equations exist for modelling semivariance patterns. A deep knowledge of these is not required to fit an empirical variogram to a model. Here are a few popular examples.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exponential&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;$$ \gamma (h) = \begin{cases}0 &amp;amp; \text{if }h=0 \\&lt;br&gt;
C_0+C_1 \left [ 1-e^{-(\frac{h}{r}) } \right] &amp;amp; \text{if } h&amp;gt;0 \end{cases}$$&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;$$ C_0 = nugget $$
$$ C_1 = partial : sill $$
$$ r = range $$&lt;/p&gt;














&lt;figure  id=&#34;figure-theoretical-exponential-variogram&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Theoretical Exponential Variogram&#34; srcset=&#34;
               /media/exponential_hu386e53d67d764d7444b0b387b4e063d4_9112_ddf7cdfd8b98e26c9d3054149e89356a.png 400w,
               /media/exponential_hu386e53d67d764d7444b0b387b4e063d4_9112_a87e02bb556b883dd58f6f07653f1b3d.png 760w,
               /media/exponential_hu386e53d67d764d7444b0b387b4e063d4_9112_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/exponential_hu386e53d67d764d7444b0b387b4e063d4_9112_ddf7cdfd8b98e26c9d3054149e89356a.png&#34;
               width=&#34;760&#34;
               height=&#34;570&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Theoretical Exponential Variogram
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Gaussian&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(a squared version of the exponential model)&lt;/p&gt;
&lt;p&gt;$$ \gamma (h) = \begin{cases}0 &amp;amp; \text{if }h=0, \\&lt;br&gt;
C_0+C_1 \left [ 1-e^{-(\frac{h}{r})^2} \right] &amp;amp; \text{if } h&amp;gt;0 \end{cases}$$&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;$$ C_0 = nugget $$
$$ C_1 = partial : sill $$
$$ r = range $$&lt;/p&gt;














&lt;figure  id=&#34;figure-theoretical-gaussian-variogram&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Theoretical Gaussian Variogram&#34; srcset=&#34;
               /media/gaussian_hu2f658028d7284d4383fb0ced7f818ca1_9293_cff44df779d4cf946b5347a882e571f0.png 400w,
               /media/gaussian_hu2f658028d7284d4383fb0ced7f818ca1_9293_0aa29f0aef9676f3097de237b30e8d5b.png 760w,
               /media/gaussian_hu2f658028d7284d4383fb0ced7f818ca1_9293_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/gaussian_hu2f658028d7284d4383fb0ced7f818ca1_9293_cff44df779d4cf946b5347a882e571f0.png&#34;
               width=&#34;760&#34;
               height=&#34;570&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Theoretical Gaussian Variogram
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Matérn&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;lt;/An extremely complicated mathematical model/&amp;gt;&lt;/em&gt;&lt;/p&gt;














&lt;figure  id=&#34;figure-empirical-matérn-variogram&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Empirical Matérn Variogram&#34; srcset=&#34;
               /media/matern_example_hu3509d66db1bd03bfa15b6cd033f73cb0_11816_469234f2912ae9c7d5d274e0e93e1e8b.png 400w,
               /media/matern_example_hu3509d66db1bd03bfa15b6cd033f73cb0_11816_9fb3a5401309369250e4aee537db6ab2.png 760w,
               /media/matern_example_hu3509d66db1bd03bfa15b6cd033f73cb0_11816_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/matern_example_hu3509d66db1bd03bfa15b6cd033f73cb0_11816_469234f2912ae9c7d5d274e0e93e1e8b.png&#34;
               width=&#34;760&#34;
               height=&#34;543&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Empirical Matérn Variogram
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;There are many more models: Cauchy, logistic, spherical, sine, &amp;hellip;.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    For more information on these models, see this workshop&amp;rsquo;s accompanying &lt;a href=&#34;https://idahoagstats.github.io/guide-to-field-trial-spatial-analysis/background.html&#34;&gt;online book&lt;/a&gt; on this topic and additional &lt;a href=&#34;http://documentation.sas.com/doc/en/pgmsascdc/9.4_3.4/statug/statug_variogram_details02.htm&#34;&gt;SAS resources&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;variogram-fitting&#34;&gt;Variogram fitting&lt;/h3&gt;
&lt;p&gt;Picking the right model is done both by comparing the sum of squares of error for different models and by&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Not all variables have spatial autocorrelation&lt;/strong&gt;&lt;/p&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/bad_variogram_hued4982af248a0925e63ca33cf80a5a32_29378_fc15314aec043527ef960b706ff65911.png 400w,
               /media/bad_variogram_hued4982af248a0925e63ca33cf80a5a32_29378_278189afe3dd801b3e5a39d434aa0f53.png 760w,
               /media/bad_variogram_hued4982af248a0925e63ca33cf80a5a32_29378_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/bad_variogram_hued4982af248a0925e63ca33cf80a5a32_29378_fc15314aec043527ef960b706ff65911.png&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Not all fitted variogram models are worthy&lt;/strong&gt;&lt;/p&gt;














&lt;figure  id=&#34;figure-variogram-gone-bad&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Variogram gone bad&#34; srcset=&#34;
               /media/bad_variogram2_hubb2acf3376379e20deaeda13cbc7af2d_140991_528362d3ba3fefa9f526ab216ad0b8a3.png 400w,
               /media/bad_variogram2_hubb2acf3376379e20deaeda13cbc7af2d_140991_963c2ba2c995fb232ec6b036ac661d9b.png 760w,
               /media/bad_variogram2_hubb2acf3376379e20deaeda13cbc7af2d_140991_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/bad_variogram2_hubb2acf3376379e20deaeda13cbc7af2d_140991_528362d3ba3fefa9f526ab216ad0b8a3.png&#34;
               width=&#34;760&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Variogram gone bad
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;h3 id=&#34;code-for-this-section&#34;&gt;Code for this section&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;The following scripts build upon work done in previous section(s).&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-7&#34;&gt;
  &lt;summary&gt;R&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;# load libraries
library(gstat); library(spaMM)

# set up spatial object
Nin_spatial &amp;lt;- Nin_na
coordinates(Nin_spatial) &amp;lt;- ~ col.width + row.length # add attribte
class(Nin_spatial)

# establish max distance for variogram estimation
max_dist = 0.6*max(dist(coordinates(Nin_spatial)))

# calculate empirical variogram
resid_var1 &amp;lt;- gstat::variogram(yield ~ rep + gen, 
                        cutoff = max_dist,
                        width = max_dist/15, # 15 is the number of bins
                        data = Nin_spatial)
plot(resid_var1)  # empirical variogram

#Note: To fit a large number of models, the function &#39;autofitVariogram()&#39; from the package automap can be used (is it calling gstat::variogram)

# starting value for the nugget
nugget_start &amp;lt;- min(resid_var1$gamma) 

# initialise the model (this does not do much)
Nin_vgm_exp &amp;lt;- vgm(model = &amp;quot;Exp&amp;quot;, nugget = nugget_start) # exponential
Nin_vgm_gau &amp;lt;- vgm(model = &amp;quot;Gau&amp;quot;, nugget = nugget_start) # Gaussian
Nin_vgm_mat &amp;lt;- vgm(model = &amp;quot;Mat&amp;quot;, nugget = nugget_start) # Matern

# actually do some fitting! 
Nin_variofit_exp &amp;lt;- fit.variogram(resid_var1, Nin_vgm_exp)
Nin_variofit_gau &amp;lt;- fit.variogram(resid_var1, Nin_vgm_gau)
Nin_variofit_mat &amp;lt;- fit.variogram(resid_var1, Nin_vgm_mat, fit.kappa = T)

plot(resid_var1, Nin_variofit_exp, main = &amp;quot;Exponential model&amp;quot;)
plot(resid_var1, Nin_variofit_gau, main = &amp;quot;Gaussian model&amp;quot;)
plot(resid_var1, Nin_variofit_mat, main = &amp;quot;Matern model&amp;quot;) 

attr(Nin_variofit_exp, &amp;quot;SSErr&amp;quot;)
attr(Nin_variofit_gau, &amp;quot;SSErr&amp;quot;)
attr(Nin_variofit_mat, &amp;quot;SSErr&amp;quot;)

# parameters:
Nin_variofit_gau

nugget &amp;lt;- Nin_variofit_gau$psill[1] # measurement error (other random error)
range &amp;lt;- Nin_variofit_gau$range[2] # distance to establish independence between data points
sill &amp;lt;- sum(Nin_variofit_gau$psill) # maximum semivariance
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-8&#34;&gt;
  &lt;summary&gt;SAS&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;# calculate semivariance and compute empirical variogram
proc variogram data=residuals plots(only)=(semivar);
   coordinates xc=Col yc=Row;
   compute lagd=1.2 maxlags=30;
  var resid;
run;

# fit models to the empirical variogram
proc variogram data=residuals plots(only)=(fitplot);
   coordinates xc=Col yc=Row;
   compute lagd=1.2 maxlags=30;
   model form=auto(mlist=(gau, exp, pow, sph) nest=1);
  var resid;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
</description>
    </item>
    
    <item>
      <title>Visualization</title>
      <link>/draft-workshops/example/visualization/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>/draft-workshops/example/visualization/</guid>
      <description>&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/hSPmj7mK6ng&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;When is a heatmap useful?&lt;/summary&gt;
  &lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Write Plotly code to render a bar chart&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import plotly.express as px
data_canada = px.data.gapminder().query(&amp;quot;country == &#39;Canada&#39;&amp;quot;)
fig = px.bar(data_canada, x=&#39;year&#39;, y=&#39;pop&#39;)
fig.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Linear Models with Correlated Errors</title>
      <link>/workshops/spatial-workshop/correlated-error-models/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/workshops/spatial-workshop/correlated-error-models/</guid>
      <description>&lt;p&gt;Now that we have a sense of how to model spatial variation, the next step is to incorporate that into a linear model. The starting point is the linear mixed model. In RCBD design, often the treatments are treated as fixed and the block effect as random.&lt;/p&gt;
&lt;p&gt;$$Y_ij = \mu + \alpha_i + \beta_j + \epsilon_{ij}$$&lt;/p&gt;
&lt;p&gt;$Y_ij$ is the independent variable&lt;br&gt;
$\mu$ is the overall mean&lt;br&gt;
$\alpha_i$ is the effect due to the $i^{th}$ treatment&lt;br&gt;
$\beta_j$ is the effect due to the $j^{th}$ block&lt;br&gt;
$\epsilon_{ij}$ are the error terms distributed as $N ~\sim (0,\sigma)$&lt;/p&gt;
&lt;p&gt;Here is an expanded version of the last term:&lt;/p&gt;
&lt;p&gt;$$  \epsilon_{ij} ~\sim N \Bigg( 0,
\left[ { \begin{array}{ccc} \sigma &amp;amp; \cdots &amp;amp; 0 \\&lt;br&gt;
\vdots &amp;amp; \ddots &amp;amp; \vdots \\&lt;br&gt;
0 &amp;amp; \cdots &amp;amp; \sigma \end{array} } \right] \Bigg) $$&lt;/p&gt;
&lt;p&gt;This is a mathematically representation of &lt;strong&gt;iid&lt;/strong&gt;, independent and identically distributed, an assumption of linear models. When there is spatial autocorrelation, observations closer to one another are correlated, so the off-diagonals in the variance-covariance matrix are not zero.&lt;/p&gt;
&lt;p&gt;Spatial models seek to mathematically model this covariance so it is properly accounted for during hypothesis testing and prediction.&lt;/p&gt;
&lt;h3 id=&#34;code-for-this-section&#34;&gt;Code for this section&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;The following scripts build upon work done in previous section(s).&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-0&#34;&gt;
  &lt;summary&gt;R&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;library(emmeans); library()
# (nlme and gstat should already be loaded)
library(spaMM) # for running `corMatern()`

# standard linear model
nin_lme &amp;lt;- lme(yield ~ gen, random = ~1|rep,
              data = Nin,
              na.action = na.exclude)
              
# extract the esimated marginal means for variety
preds_lme &amp;lt;- as.data.frame(emmeans(nin_lme, &amp;quot;gen&amp;quot;))

# use information from the variogram fitting for intialising the parameters
nugget &amp;lt;- Nin_variofit_gau$psill[1] 
range &amp;lt;- Nin_variofit_gau$range[2]  
sill &amp;lt;- sum(Nin_variofit_gau$psill) 
nugget.effect &amp;lt;-  nugget/sill

# initalise the covariance structure (from the nlme package)
cor.gaus &amp;lt;- corSpatial(value = c(range, nugget.effect), 
                  form = ~ row.length + col.width, 
                  nugget = T, fixed = F,
                  type = &amp;quot;gaussian&amp;quot;, 
                  metric = &amp;quot;euclidean&amp;quot;)

# update the rcbd model
nin_gaus &amp;lt;- update(nin_lme, corr = cor.gaus)
# extract predictions for &#39;gen&#39;
preds_gaus &amp;lt;- as.data.frame(emmeans(nin_gaus, &amp;quot;gen&amp;quot;)

# a similar procedure can be follow for other models
# but we are going to take a shortcut and not specify the parameters

# exponential
cor.exp &amp;lt;- corSpatial(form = ~ row.length + col.width, 
                      nugget = T, fixed = F)

nin_exp &amp;lt;- update(nin_lme, corr = cor.exp)
preds_exp &amp;lt;- as.data.frame(emmeans(nin_exp, &amp;quot;gen&amp;quot;))

# Matern structure
cor.mat &amp;lt;- corMatern(form = ~ row.length + col.width, 
                     nugget = T, fixed = F)
nin_matern &amp;lt;- update(nin_lme, corr = cor.mat)
preds_mat &amp;lt;- as.data.frame(emmeans(nin_matern, &amp;quot;gen&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;SAS&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;proc mixed data=alliance ;
	class entry rep;
	model yield = entry ;
	random rep;
	lsmeans entry/cl;
	ods output LSMeans=NIN_RCBD_means;
	title1 &#39;NIN data: RCBD&#39;;
run;

proc mixed data=alliance maxiter=150;
	class entry;
	model yield = entry /ddfm=kr;
	repeated/subject=intercept type=sp(gau) (Row Col) local;
	parms (11) (22) (19);
	lsmeans entry/cl;
	ods output LSMeans=NIN_Spatial_means;
	title1 &#39;NIN data: Gaussian Spatial Adjustment&#39;;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
</description>
    </item>
    
    <item>
      <title>Statistics</title>
      <link>/draft-workshops/example/stats/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>/draft-workshops/example/stats/</guid>
      <description>&lt;p&gt;Introduction to statistics for data science.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;
&lt;p&gt;The general form of the &lt;strong&gt;normal&lt;/strong&gt; probability density function is:&lt;/p&gt;
&lt;p&gt;$$
f(x) = \frac{1}{\sigma \sqrt{2\pi} } e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
$$&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;What is the parameter $\mu$?&lt;/summary&gt;
  &lt;p&gt;The parameter $\mu$ is the mean or expectation of the distribution.&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Modelling Spatial Trends</title>
      <link>/workshops/spatial-workshop/trend-modelling/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/workshops/spatial-workshop/trend-modelling/</guid>
      <description>&lt;p&gt;The spatial models introduced in this workshop assume that spatial variation is localised and within a trial, plots located sufficiently far apart are independent of each other with no apparent spatial correlation. However, sometimes that is accurately describe a field trial. There can be experiment-wide gradients due to position on a slope, proximity to an influential environmental factor (e.g. a road), and so on. In these instances, those gradients should be modelled as a trend.&lt;/p&gt;
&lt;h3 id=&#34;blocking&#34;&gt;Blocking&lt;/h3&gt;
&lt;p&gt;Blocking is one example of modelling an experiment wide-trend:&lt;/p&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/blocking_hu10ad972e63ec33f6cccede6b15d61278_254605_d4a9434e4d64be2fa5ae0fabbb1a7d9f.png 400w,
               /media/blocking_hu10ad972e63ec33f6cccede6b15d61278_254605_cc366fc98ad7465ff769b5f4863a991d.png 760w,
               /media/blocking_hu10ad972e63ec33f6cccede6b15d61278_254605_1200x1200_fit_lanczos_2.png 1200w&#34;
               src=&#34;/media/blocking_hu10ad972e63ec33f6cccede6b15d61278_254605_d4a9434e4d64be2fa5ae0fabbb1a7d9f.png&#34;
               width=&#34;760&#34;
               height=&#34;434&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;The expectation is that each block will capture and model existing variation  within it. This becomes difficult to justify as blocks become large.&lt;/p&gt;
&lt;h3 id=&#34;rows--ranges&#34;&gt;Rows &amp;amp; Ranges&lt;/h3&gt;
&lt;p&gt;Recall the RCBD model from the previous section:&lt;/p&gt;
&lt;p&gt;$$Y_ij = \mu + \alpha_i + \beta_j + \epsilon_{ij}$$&lt;/p&gt;
&lt;p&gt;Trials rows and ranges can likewise be modelled directly through expansion of that model (and omitting block since it full represented by column):&lt;/p&gt;
&lt;p&gt;$$Y_ijk = \mu + \alpha_i + \beta_j + \gamma_k + \epsilon_{ijk}$$&lt;/p&gt;
&lt;p&gt;$Y_ij$ is the independent variable&lt;br&gt;
$\mu$ is the overall mean&lt;br&gt;
$\alpha_i$ is the effect due to the $i^{th}$ treatment&lt;br&gt;
$\beta_j$ is the effect due to the $j^{th}$ row  &lt;br&gt;
$\gamma_k$ is the effect due to the $k^{th}$ range (or column)&lt;br&gt;
$\epsilon_{ij}$ are the error terms distributed as $N ~\sim (0,\sigma)&lt;/p&gt;
&lt;h4 id=&#34;code-for-trends&#34;&gt;Code for Trends&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;The following scripts build upon work done in previous section(s).&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;R&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;# load libraries
library(lme4)

# exploratory plots 
boxplot(yield ~ rep, data = Nin, xlab = &amp;quot;block&amp;quot;, col = &amp;quot;red2&amp;quot;)
boxplot(yield ~ row, data = Nin, xlab = &amp;quot;row&amp;quot;, col = &amp;quot;dodgerblue2&amp;quot;)
boxplot(yield ~ col, data = Nin, xlab = &amp;quot;column&amp;quot;, col = &amp;quot;gold&amp;quot;)

## row/column model ##

# data prep
Nin$rowF = as.factor(Nin$row)
Nin$colF = as.factor(Nin$col)

# specify model
nin.rc &amp;lt;- lmer(yield ~ gen + (1|colfF) + (1|rowF),
              data = Nin, na.action = na.exclude)
# extract random effects for row and column
ranef(nin_rc)
# extract predictions
nin_rc &amp;lt;- as.data.frame(emmeans(nin.rc, &amp;quot;gen&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;SAS&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;# exploratory boxplots
proc sgplot data=alliance;
    vbox yield/category=rep FILLATTRS=(color=red) LINEATTRS=(color=black) WHISKERATTRS=(color=black);
run;

proc sgplot data=alliance;
    vbox yield/category=Col FILLATTRS=(color=yellow) LINEATTRS=(color=black) WHISKERATTRS=(color=black);
run;

proc sgplot data=alliance;
    vbox yield/category=Row FILLATTRS=(color=blue) LINEATTRS=(color=black) WHISKERATTRS=(color=black);
run;

# row/column model
proc mixed data=alliance ;
	class entry rep;
	model yield = entry  row col/ddfm=kr;
	random rep;
	lsmeans entry/cl;
	ods output LSMeans=NIN_row_col_means;
	title1 &#39;NIN data: RCBD&#39;;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;h3 id=&#34;splines&#34;&gt;Splines&lt;/h3&gt;
&lt;p&gt;Polynomial splines are an additional method for spatial adjustment and represent a more non-parametric method that does not rely on estimation or modeling of variograms. Instead, it uses the raw data and residuals to fit a surface to the spatial data and adjust the variance covariance matrix accordingly.&lt;/p&gt;
&lt;h4 id=&#34;code-for-splines&#34;&gt;Code for Splines&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;The following scripts build upon work done in previous section(s).&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;R&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;nin_spline &amp;lt;- SpATS(response = &amp;quot;yield&amp;quot;, 
                    spatial = ~ PSANOVA(col, row, nseg = c(10,20),
                                        degree = 3, pord = 2), 
                    genotype = &amp;quot;gen&amp;quot;,  
                    random = ~ rep, # + rowF + colF, 
                    data = Nin, 
                    control = list(tolerance = 1e-03, monitoring = 0))
                    
preds_spline &amp;lt;- predict(nin_spline, which = &amp;quot;gen&amp;quot;) %&amp;gt;% 
  dplyr::select(gen, emmean = &amp;quot;predicted.values&amp;quot;, SE = &amp;quot;standard.errors&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;SAS&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;proc glimmix data=alliance ;
    class entry rep;
    effect sp_r = spline(row col);
    model yield = entry  sp_r/ddfm=kr;
    random row col/type=rsmooth;
    lsmeans entry/cl;
    ods output LSMeans=NIN_smooth_means;
    title1 &#39;NIN data: RCBD&#39;;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
</description>
    </item>
    
    <item>
      <title>Comparing Models</title>
      <link>/workshops/spatial-workshop/model-comparison/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/workshops/spatial-workshop/model-comparison/</guid>
      <description>&lt;p&gt;Now that we have built these spatial models, how do we pick the right one? Unfortunately, there is no one model that works best in all circumstances. In addition, there is no single way for choosing the best model. Some approaches include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Comparing model fitness (e.g. AIC, BIC, log likelihood). Although the methods are not nested, hence precluding a log likelihood ratio test, we can compare raw values for each fit statistic. Be careful doing this in R since linear modelling packages use different estimation procedures for maximum likelihood and REML estimation that are not comparable.&lt;/li&gt;
&lt;li&gt;Comparing post-hoc power (that is, the p-values for the treatments)&lt;/li&gt;
&lt;li&gt;Comparing standard error of the estimates (i.e. precision)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Comparing changes in the coefficient of variation (CV, $\sigma/\mu$) is not recommended because in many spatial models, field variation has been re-partitioned to the error term when it was (erroneously) absorbed by the other experimental effects. As a result, the CV can increase in spatial models even when inclusion of spatial covariates results in better model fit.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Unfortunately, there is no one method for unambiguously returning the the best estimates and true ranks of the treatments. Likewise, there is no one spatial method that works best in all situations and field trials.&lt;/p&gt;
&lt;h3 id=&#34;code-for-this-section&#34;&gt;Code for this section&lt;/h3&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;R&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;library(tidyr)

# remove some objects we don&#39;t need (and will interfere with downstream processes)
rm(nin_variofit, nin_vgm)
rm(nin_vgm, nin_variofit, nugget, sill, range, nugget.effect)

# assemble objects into a list
nlme_mods &amp;lt;- list(nin_lme, nin_exp, nin_gaus, nin_matern)
names(nlme_mods) &amp;lt;- c(&amp;quot;LMM&amp;quot;, &amp;quot;exponential&amp;quot;, &amp;quot;gaussian&amp;quot;, &amp;quot;matern&amp;quot;)

# extract log likelihood, AIC, BIC
data.frame(loglik = sapply(nlme_mods, logLik),  
           AIC = sapply(nlme_mods, AIC),
           BIC = sapply(nlme_mods, AIC, k = log(nrow(Nin_na)))) %&amp;gt;% arrange(desc(loglik))
# (higher is better for loglik, lower is better for AIC and BIC)

# compare post-hoc power
# conduct ANOVA
anovas &amp;lt;- lapply(nlme_mods[-7], function(x){ 
  aov &amp;lt;- as.data.frame(anova(x))[2,]})
# bind all the output together
a &amp;lt;- bind_rows(anovas) %&amp;gt;% 
  mutate(model = c(&amp;quot;LMM&amp;quot;, &amp;quot;exponential&amp;quot;, &amp;quot;gaussian&amp;quot;, &amp;quot;matern&amp;quot;, &amp;quot;row-col&amp;quot;)) %&amp;gt;% 
  arrange(desc(`p-value`)) %&amp;gt;% select(c(model, 1:4)) 
rownames(a) &amp;lt;- 1:nrow(a)
a

## compare precision of estimates
all.preds &amp;lt;- mget(ls(pattern = &amp;quot;^preds_*&amp;quot;))
errors &amp;lt;- lapply(all.preds, &amp;quot;[&amp;quot;, &amp;quot;SE&amp;quot;)
pred.names &amp;lt;- gsub(&amp;quot;preds_&amp;quot;, &amp;quot;&amp;quot;, names(errors))
error_df &amp;lt;- bind_cols(errors)
colnames(error_df) &amp;lt;- pred.names
boxplot(error_df, ylab = &amp;quot;standard errors&amp;quot;, xlab = &amp;quot;linear model&amp;quot;, 
        col = &amp;quot;dodgerblue3&amp;quot;)

# compare predictions 
preds &amp;lt;- lapply(all.preds, &amp;quot;[&amp;quot;, &amp;quot;emmean&amp;quot;)
preds_df &amp;lt;- bind_cols(preds)
colnames(preds_df) &amp;lt;- pred.names
preds_df$gen &amp;lt;- preds_exp$gen

# plot changes in rank
lev &amp;lt;- c(&amp;quot;lme&amp;quot;, &amp;quot;exp&amp;quot;, &amp;quot;gaus&amp;quot;, &amp;quot;mat&amp;quot;)
pivot_longer(preds_df, cols = !gen, names_to = &amp;quot;model&amp;quot;, values_to = &amp;quot;emmeans&amp;quot;) %&amp;gt;% 
  mutate(model = factor(model, levels = lev)) %&amp;gt;% 
  ggplot(aes(x = model, y = emmeans, group = gen)) +
  geom_point(size = 5, alpha = 0.5, col = &amp;quot;navy&amp;quot;) +
  geom_line() +
  ylab(&amp;quot;yield means for gen&amp;quot;) + 
  theme_minimal()
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;SAS&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;data NIN_RCBD_means (drop=tvalue probt alpha estimate stderr lower upper df);
	set NIN_RCBD_means;
	RCB_est = estimate;
	RCB_se = stderr;
run;

data NIN_Spatial_means (drop=tvalue probt alpha estimate stderr lower upper df);
	set NIN_Spatial_means;
	Sp_est = estimate;
	Sp_se = stderr;
run;

proc sort data=NIN_RCBD_means;
	by entry;
run;

proc sort data=NIN_Spatial_means;
	by entry;
run;

data compare;
	merge NIN_RCBD_means NIN_Spatial_means;
	by entry;
run;

proc rank data=compare out=compare descending;
	var RCB_est Sp_est;
	ranks RCB_Rank Sp_Rank;
run;

proc sort data=compare;
	by  Sp_rank;
run;

proc print data=compare(obs=15);
	var entry rcb_est Sp_est rcb_se sp_se rcb_rank sp_rank;
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
</description>
    </item>
    
    <item>
      <title>Augmented Designs</title>
      <link>/workshops/spatial-workshop/augmented/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/workshops/spatial-workshop/augmented/</guid>
      <description>&lt;p&gt;The augmented experimental design is a special design where there is a large number of unreplicated plots interspersed with frequent checks that are replicated. This type of model is  useful when the number of treatments is very large and/or replication is either impossible or unfeasible. Often, the primary goal of the studies using this design is to rank or select genotypes.&lt;/p&gt;
&lt;p&gt;Augmented models are analyzed in a fundamentally different method than RCBD models due to the large number of unreplicated observations. To adjust for the lack of replication, only a select set of treatments, usually of known performance, are replicated in the experiments. The error estimated from these replicated treatments is used in the analysis to evaluate the remaining genotypes.&lt;/p&gt;
&lt;p&gt;There are multiple way to specify an augmented model depending on what the researcher wants to know.&lt;/p&gt;
&lt;h3 id=&#34;model-specification-1&#34;&gt;Model specification #1&lt;/h3&gt;
&lt;p&gt;$$ Y_{ij} = \tau_i + \beta(\tau)_{ij} $$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$ Y_{ij}$ is the response variable&lt;/li&gt;
&lt;li&gt;$ \tau_i$ is the effect of each check and the average effect of all unreplicated treatments&lt;/li&gt;
&lt;li&gt;$ \beta(\tau)_{ij}$ is is the effect of the $j^{th}$ unreplicated treatment nested within the overall effect of unreplicated treatments&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This model evaluates:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The difference between all checks and the average of the unreplicated treatments.&lt;/li&gt;
&lt;li&gt;The difference between the unreplicated treatments.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;model-specification-2&#34;&gt;Model specification #2&lt;/h3&gt;
&lt;p&gt;$$ Y_{ij} = \delta_i + \gamma(\delta)_{ij} $$&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$ Y_{ij}$ is the response variable&lt;/li&gt;
&lt;li&gt;$ \delta_i$ is the average effect of all checks and the average effect of all unreplicated treatments (so there are only 2 treatment levels)&lt;/li&gt;
&lt;li&gt;$ \gamma(\delta)_{ij}$ is is the effect of the $j^{th}$ treatment nested within the either unreplicated treatments or the check observations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This model evaluates:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The difference between the average of the checks and the average of the unreplicated treatments&lt;/li&gt;
&lt;li&gt;The difference between all treatments&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These models are described more in depth in &lt;a href=&#34;https://doi.org/10.2134/appliedstatistics.2016.0005.c13&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Burgueño et al, 2018&lt;/a&gt;, along with a helpful discussion on when to treat any of these effects as fixed or random&lt;/p&gt;
&lt;p&gt;The data used here refer to a wheat genotype evaluation study carried out near Lind Washington. The study looked at 922 unreplicated genotypes (‘name’) accompanied by 9 replicated check wheat cultivars.&lt;/p&gt;
&lt;h3 id=&#34;code-for-this-section&#34;&gt;Code for this section&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;The following scripts build upon work done in previous section(s).&lt;/em&gt;&lt;/p&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-0&#34;&gt;
  &lt;summary&gt;R&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;# (if not already loaded)
library(dplyr); library(nlme); library(ggplot2)
library(gstat); library(sp)

# read in data
aug_data_origin &amp;lt;- read.csv(&amp;quot;data/augmented_lind.csv&amp;quot;, 
                            na.strings = c(&amp;quot;&amp;quot;, &amp;quot;NA&amp;quot;, &amp;quot;.&amp;quot;, &amp;quot;999999&amp;quot;)) %&amp;gt;% 
  slice(-1) %&amp;gt;% # first line not needed
  mutate(yieldkg = yieldg/1000)  # to prevent overflow

# summarise the genoytypic data by checks/not checks
gen_sum &amp;lt;- group_by(aug_data_origin, name) %&amp;gt;% summarise(counts = n()) %&amp;gt;% 
  mutate(delta =  case_when(
    counts &amp;gt; 1 ~ &amp;quot;check&amp;quot;,
    counts == 1 ~ &amp;quot;unrep&amp;quot;))

# need info on just the checks
checks &amp;lt;- gen_sum %&amp;gt;% filter(delta == &amp;quot;check&amp;quot;) 

# more summarise steps for different augmented modes
gen_sum2 &amp;lt;- gen_sum  %&amp;gt;%  mutate(gamma = name) %&amp;gt;% 
  mutate(tau = case_when(
    delta == &amp;quot;check&amp;quot; ~ gamma,
    delta == &amp;quot;unrep&amp;quot; ~ &amp;quot;unreplicate_obs&amp;quot;)) %&amp;gt;% 
  mutate(beta = case_when(
    delta == &amp;quot;unrep&amp;quot; ~ gamma,
    delta == &amp;quot;check&amp;quot; ~ gamma))

# merge original data set with info on treatment levels
aug_data &amp;lt;- aug_data_origin %&amp;gt;% 
  select(name, prow, pcol, yieldkg, yieldg) %&amp;gt;%
  mutate(row = prow*11.7, col = pcol*5.5) %&amp;gt;% 
  full_join(gen_sum2, by = &amp;quot;name&amp;quot;) 

## modelling

aug1 &amp;lt;- lme(fixed = yieldg ~ tau,
            random = ~ 1|tau/beta,
            data = aug_data, na.action = na.exclude)

# extract residuals
aug_data$res &amp;lt;- residuals(aug1)

# plot residual chloroepleth map:
ggplot(aug_data, aes(y = row, x = col)) +
  geom_tile(aes(fill = res)) +
  scale_fill_gradient(low = &amp;quot;yellow&amp;quot;, high = &amp;quot;black&amp;quot;) +
  scale_x_continuous(breaks = seq(1,max(aug_data$row), 1)) +
  scale_y_continuous(breaks = 1:max(aug_data$col)) +
  coord_equal() +
  theme_void() 

# add spatial covariates
aug_spatial &amp;lt;- aug_data %&amp;gt;% filter(!is.na(res))
coordinates(aug_spatial) &amp;lt;- ~ col + row
max_dist = 0.5*max(dist(coordinates(aug_spatial)))

aug_vario &amp;lt;- gstat::variogram(res ~ 1, 
                              cutoff = max_dist,
                              width = max_dist/10, 
                              data = aug_spatial)

# optional to run: 
nugget_start &amp;lt;- min(aug_vario$gamma)
aug_vgm &amp;lt;- vgm(model = &amp;quot;Exp&amp;quot;, nugget = nugget_start)
aug_variofit &amp;lt;- fit.variogram(aug_vario, aug_vgm)
plot(aug_vario, aug_variofit, main = &amp;quot;Exponential model&amp;quot;)

cor_exp &amp;lt;- corSpatial(form = ~ row + col, 
                      nugget = T, fixed = F,
                      type = &amp;quot;exponential&amp;quot;)

aug1_sp &amp;lt;- update(aug1, corr = cor_exp)

# spatial parameters:
aug1_sp$modelStruct$corStruct

# extract BLUPs for unreplicated lines:
aug1_blups &amp;lt;- ranef(aug1_sp)$beta %&amp;gt;% rename(yieldg = &#39;(Intercept)&#39;)

# look at variance components
VarCorr(aug1_sp)

##### OR #######

# another formulation
# delta estimates effects of replicated versus unreplicated genotypes
# gamma estimates the effecs of all genotypes evaluated in the trial
aug2 &amp;lt;- lme(fixed = yieldkg ~ delta,
            random = ~ 1|delta/gamma,
            data = aug_data, na.action = na.exclude)

aug2_sp &amp;lt;- update(aug2, corr = cor_exp)

# spatial parameters:
aug2_sp$modelStruct$corStruct

# extract BLUPs for unreplicated lines:
aug_blups2 &amp;lt;- ranef(aug2_sp)$gamma %&amp;gt;% rename(yieldg = &#39;(Intercept)&#39;)

# look at variance components
VarCorr(aug1_sp)
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;SAS&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code&gt;filename AUG url &amp;quot;https://raw.githubusercontent.com/IdahoAgStats/guide-to-field-trial-spatial-analysis/master/data/AB19F5_LIND.csv&amp;quot;;

PROC IMPORT OUT= WORK.augmented
     DATAFILE= AUG
     DBMS=CSV REPLACE;
     GETNAMES=YES;
     DATAROW=2; 
RUN;

data augmented;
	set augmented;
	if yieldg = 999999 or yieldg=. then delete; /* Remove missing values */
	prow=prow*11.7; /*convert row and column indices to feet */
	pcol=pcol*5.5;
run;

proc freq noprint data=augmented;
	tables name/out=controls;
run;

data controls;
	set controls;
	if count &amp;gt;1;
run;

proc sort data=controls;
	by name;
run;
     
proc sort data=augmented;
	by name;
run;

data augmented;
	merge augmented controls;
	by name;
	if count=. then d2=2; /* Unreplicated */
	else d2=1;            /* Replicated */
	yieldkg=yieldg/1000;
run;

PROC mixed data=augmented;
	class name d2;
	model yieldkg = d2/noint outp=residuals ddf=229 229;
	lsmeans d2;
	*lsmeans name(d2)/slice = d2;
run;

proc sgplot data=residuals;
	HEATMAPPARM y=pRow x=pCol COLORRESPONSE=resid/ colormodel=(cx014458 cx1E8C6E cxE1FE01); 
title1 &#39;Field Map&#39;;
run;

proc variogram data=residuals plots(only)=(fitplot);
   where yieldkg ^= .;
   coordinates xc=pcol yc=pRow;
   compute lagd=6.6 maxlags=25;
   model form=auto(mlist=(gau, exp, pow, sph) nest=1);
  var resid;
run;

PROC mixed data=augmented;
	class name d2;
	model yieldkg = d2 name(d2)/outp=adjresiduals ddf=229 229;
	lsmeans d2;
	repeated/subject=intercept type=sp(pow)(prow pcol) local;
	ods output SolutionR =parms;
	parms (0.074) (0.0051)(0.475)  ;
	*lsmeans name(d2)/slice = d2;  # alot of output!!
run;
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
</description>
    </item>
    
    <item>
      <title>Final thoughts</title>
      <link>/workshops/spatial-workshop/conclusion/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/workshops/spatial-workshop/conclusion/</guid>
      <description>&lt;p&gt;Spatial analysis can be challenging, but I think it is worth the effort to learn and implement in analysis of field trials. Incorporating spatial statistics into analysis of feel trials can be overwhelming at time. However, investigating spatial correlation in a field trial and controlling for it if necessary using &lt;em&gt;any&lt;/em&gt; of the methods developed for this is recommended over doing nothing.&lt;/p&gt;
&lt;p&gt;There is no denying that work is needed to develop scripts that automate this process so researchers can routinely incorporate spatial covariance into field trial analysis. Many current R tools are unwieldy to use and have insufficient options to support variety trial analysis.&lt;/p&gt;
&lt;p&gt;Until this situation is improved, it is probably wisest to focus on using spatial models that are well-supported at this time. Any of the options implemented in the &lt;strong&gt;nlme&lt;/strong&gt; package (or that work with that package) are decent choices with excellent support for extracting least-squares means, running ANOVA, and standard model diagnostics. Furthermore, &lt;strong&gt;nlme&lt;/strong&gt; supports generalized linear models. &lt;strong&gt;INLA&lt;/strong&gt; is established is supported by a large and growing user base, and &lt;strong&gt;breedR&lt;/strong&gt; is likewise well established.&lt;/p&gt;
&lt;h3 id=&#34;other-resources&#34;&gt;Other resources&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://idahoagstats.github.io/guide-to-field-trial-spatial-analysis/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Incorporating Spatial Analysis into Agricultural Field Experiments&lt;/a&gt;, a more comprehensive version of this tutorial&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CRAN task view on &lt;a href=&#34;https://cran.r-project.org/web/views/Spatial.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;analysis of spatial data&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Other R packages&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;package&lt;/th&gt;
&lt;th&gt;usage&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;http://famuvie.github.io/breedR/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;breedR&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;mixed modelling with AR1xAR1 estimation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.r-inla.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;inla&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Bayesian modelling with options for spatial covariance structure&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cran/McSpatial&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mcspatial&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;nonparametric spatial analysis, (no longer on CRAN)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=ngspatial&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ngspatial&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;spatial models with a focus on generalized linear models&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://CRAN.R-project.org/package=sommer&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sommer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;mixed models, including an AR1xAr1 model&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://gitlab.mbb.univ-montp2.fr/francois/spamm-ref&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;spamm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Matérn covariance structure&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/lrcastro/spANOVA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;spANOVA&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;spatial lag models for field trials&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://r-spatial.github.io/spatialreg/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;spatialreg&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;spatial functions for areal data&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The package &lt;strong&gt;sommer&lt;/strong&gt; implements a version of the AR1xAR1 covariance structure. However, it does not estimate the parameter $\rho$. The user must specify the $\rho$ and that value is not optimized in the restricted maximum likelihood estimation. Both &lt;strong&gt;BreedR&lt;/strong&gt; and &lt;strong&gt;inla&lt;/strong&gt; implement an AR1xAR1 covariance structure. Additional, SAS and the proprietary software &lt;a href=&#34;https://asreml.kb.vsni.co.uk/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;asreml&lt;/a&gt; can implement a mixed model with this covariance structure.&lt;/p&gt;
&lt;h3 id=&#34;books-for-the-deep-dive&#34;&gt;Books for the deep dive&lt;/h3&gt;














&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/cressie_revised_hu68b06343b1fbcd2ddc04942b3b381960_38587_800cbb8726c4de125424ad445947b1eb.jpg 400w,
               /media/cressie_revised_hu68b06343b1fbcd2ddc04942b3b381960_38587_bd57d203adefa7bd4d34132f8dafda5d.jpg 760w,
               /media/cressie_revised_hu68b06343b1fbcd2ddc04942b3b381960_38587_1200x1200_fit_q75_lanczos.jpg 1200w&#34;
               src=&#34;/media/cressie_revised_hu68b06343b1fbcd2ddc04942b3b381960_38587_800cbb8726c4de125424ad445947b1eb.jpg&#34;
               width=&#34;250&#34;
               height=&#34;250&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/book/10.1002/9781119115151&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Statistics for Spatial Data&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Applied Spatial Data Analysis with R&lt;/strong&gt;, available for &lt;a href=&#34;https://asdar-book.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;free&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://spacetimewithr.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Spatio-Temporal Statistics With R&lt;/strong&gt;&lt;/a&gt; (also free)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.routledge.com/Spatial-Data-Analysis-in-Ecology-and-Agriculture-Using-R/Plant/p/book/9780367732325&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Spatial Data Analysis in Ecology and Agriculture Using R&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Applied ANOVA in R</title>
      <link>/post/anova-in-r/</link>
      <pubDate>Wed, 17 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/post/anova-in-r/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;p_values.png&#34; alt=&#34;xkcd commentary on p-values&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;ANOVA in R is a unfortunately a bit complicated. Unlike SAS, ANOVA functions in R lack a consistent structure, consistent output and the accessory packages for ANOVA display a patchwork of compatibility. The result is that it is easy to misspecify a model or make other mistakes. The information below is intended to serve as a guide through the R ANOVA wilderness.&lt;/p&gt;
&lt;h4 id=&#34;packages-needed&#34;&gt;Packages Needed&lt;/h4&gt;
&lt;p&gt;There are many packages to load. Here is a (very) brief summary of what each package does.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Package&lt;/th&gt;
&lt;th&gt;Purpose&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;car&lt;/td&gt;
&lt;td&gt;Anova() function to extract type III &amp;amp; II sums of squares&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;lme4&lt;/td&gt;
&lt;td&gt;mixed models&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;nlme&lt;/td&gt;
&lt;td&gt;mixed models, non-linear models, alternative covariance structures&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;emmeans&lt;/td&gt;
&lt;td&gt;for extracting least squares means and contrasts&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;lmer test&lt;/td&gt;
&lt;td&gt;improved summary functions of lmer objects&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;dplyr&lt;/td&gt;
&lt;td&gt;data organization&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;forcats&lt;/td&gt;
&lt;td&gt;for managing categorical data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;agridat&lt;/td&gt;
&lt;td&gt;has many agricultural data sets&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;agricolae&lt;/td&gt;
&lt;td&gt;has options for many common agricultural experimental designs&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(car)
library(lme4)
library(nlme)
library(emmeans) #in older version of R, you may need to install &amp;quot;multcompView&amp;quot; separately to access full functionality of the emmeans package
library(lmerTest)
library(dplyr)
library(forcats)
library(agridat)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;formula-notation&#34;&gt;Formula Notation&lt;/h4&gt;
&lt;p&gt;There are some consistent features across ANOVA methods in R. Formula notation is often used in the R syntax for ANOVA functions. It looks like this: &lt;code&gt;$Y ~ X&lt;/code&gt;, where Y is the dependent variable (the response) and X is/are the independent variable(s) (e.g. the experimental treatments).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;my_formula &amp;lt;- formula(Y ~ treatment1 + treatment2)
class(my_formula)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;formula&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;my_formula
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Y ~ treatment1 + treatment2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Often the independent variables (i,e, the treatments or the x variables) are expected to be factors, another type of R object:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;my_var &amp;lt;- c(rep(&amp;quot;low&amp;quot;,5), rep(&amp;quot;high&amp;quot;, 5))
class(my_var) #check what variable type it is
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although &amp;ldquo;my_var&amp;rdquo; is not type factor, it is type &amp;ldquo;character&amp;rdquo; which is automatically converted to a factor in &lt;code&gt;lm()&lt;/code&gt;, &lt;code&gt;lmer()&lt;/code&gt;, &lt;code&gt;lme()&lt;/code&gt; and many other linear modeling functions. There are some packages that do not follow this convention, so it&amp;rsquo;s helpful to read function documentation, especially if you get unexpected results.&lt;/p&gt;
&lt;p&gt;Variables like year, which are often imported as a number or integer, do need to be converted to a factor or a character variable prior to analysis. Otherwise, they will be interpreted as a number in linear modelling and treated as a covariate, e.g, 2020 would be 2,020. Here is one way to do this conversion:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;my_factor &amp;lt;- as.character(my_var) # convert to a character
class(my_factor) # check variable type to confirm
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;my_factor &amp;lt;- as.factor(my_var) # convert to a factor
class(my_factor) # check variable type again to confirm
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;factor&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The choice of whether to convert a categorical variable to a character or factor depends on the comfort of the user with these structures and package requirements.&lt;/p&gt;
&lt;p&gt;Sometimes, there is a need to alter the order of treatment levels (that is, how R sees those levels). The default behavior of R is to order categorical levels alphanumerically.  However, sometimes there are reasons you may not want this (for example, you want to set a particular reference level as the first factor level).&lt;/p&gt;
&lt;p&gt;Below is one example of how to reorder factor levels in a variable. The first step is to see which levels are present in the variable and how they are ordered:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;levels(my_factor) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;high&amp;quot; &amp;quot;low&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once that is known, you can use that information to manually set the levels and their order. Note that spelling of each level much match what is actually present in the variable. Unmatched levels in the variable will be set to NA automatically by R in the following step.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;my_factor &amp;lt;- factor(my_factor, levels = c(&amp;quot;low&amp;quot;, &amp;quot;high&amp;quot;)) 
levels(my_factor) # check the new ordering
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;low&amp;quot;  &amp;quot;high&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Knowing the level order is important because in the implementation of ANOVA in R, the first level is treated as the reference level. Manipulating factors is a challenging task in R. The package &lt;a href=&#34;https://forcats.tidyverse.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;forcats&lt;/a&gt; contains a collection of accessory functions for managing factors (&amp;ldquo;forcats&amp;rdquo; = for categories). The tutorial uses the forcats function &lt;code&gt;fct_drop()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;More on formulas:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The formula first shown, &lt;code&gt;Y ~ treatment1 + treatment2&lt;/code&gt;, includes main effects only. Other formula notation includes the symbols &lt;code&gt;:&lt;/code&gt; and &lt;code&gt;*&lt;/code&gt;, indicating notation for interaction only and main effects plus the interaction term, respectively.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;formula(Y ~ treatment1:treatment2) # interaction only
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Y ~ treatment1:treatment2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;formula(Y ~ treatment1*treatment2) # interaction plus main effects
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Y ~ treatment1 * treatment2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These two formulas are equivalent:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;formula(Y ~ treatment1 + treatment2 + treatment1:treatment2) 
formula(Y ~ treatment1*treatment2) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Perhaps you can see from these examples that formulas are a really just a collections of characters (that is, a string) and exist independent of any data set. Later, we will need to link these formulas to a data set to actually construct a linear model and conduct statistical analysis.&lt;/p&gt;
&lt;h3 id=&#34;anova-for-fixed-effects-models&#34;&gt;ANOVA for fixed effects models&lt;/h3&gt;
&lt;p&gt;Here is a function for reporting the number of missing data in each column. There are other ways to do this, but I find this function easy enough to write and use.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;count_na &amp;lt;- function(df) {
  apply(df, 2, function(x) sum(is.na(x))) 
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;completely-randomised-design&#34;&gt;Completely Randomised design&lt;/h4&gt;
&lt;p&gt;First, load the data set &amp;ldquo;warpbreaks&amp;rdquo; (a data set from base R). This is an old data set with variables for wool type (A and B) and tension on the loom (L, M or H). The response variable is &amp;ldquo;breaks&amp;rdquo;, the number of times the wool thread breaks on industrial looms.&lt;/p&gt;
&lt;p&gt;I always like to have a quick look at the data before running any statistical tests. So, here we go:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(warpbreaks)
count_na(warpbreaks)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  breaks    wool tension 
##       0       0       0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;str(warpbreaks)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:	54 obs. of  3 variables:
##  $ breaks : num  26 30 54 25 70 52 51 26 67 18 ...
##  $ wool   : Factor w/ 2 levels &amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ tension: Factor w/ 3 levels &amp;quot;L&amp;quot;,&amp;quot;M&amp;quot;,&amp;quot;H&amp;quot;: 1 1 1 1 1 1 1 1 1 2 ...
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;warpbreaks$wool &amp;lt;- factor(warpbreaks$wool, levels = c(&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;))

table(warpbreaks$wool, warpbreaks$tension)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    
##     L M H
##   A 9 9 9
##   B 9 9 9
##   C 0 0 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hist(warpbreaks$breaks, col = &amp;quot;gold&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(breaks ~ wool, data = warpbreaks, col = &amp;quot;orangered&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-9-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(breaks ~ tension, data = warpbreaks, col = &amp;quot;chartreuse&amp;quot;) #why not have colorful plots?
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-9-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This data set has 2 treatments. We don&amp;rsquo;t know if there is an interaction between the variables, yet. A good start is to run a linear model using &lt;code&gt;lm()&lt;/code&gt; function, the linear regression function. As a reminder, ANOVA is a special case of the linear regression model where the predictors (the experimental treatments) are categories rather than a continuous variable.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# run standard linear model for main effects only
lm.mod1 &amp;lt;- lm(breaks ~ wool + tension, data = warpbreaks)

# extract type III sums of squares from that model
Anova(lm.mod1, type = &amp;quot;3&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Anova Table (Type III tests)
## 
## Response: breaks
##              Sum Sq Df  F value    Pr(&amp;gt;F)    
## (Intercept) 20827.0  1 154.3226 &amp;lt; 2.2e-16 ***
## wool          450.7  1   3.3393  0.073614 .  
## tension      2034.3  2   7.5367  0.001378 ** 
## Residuals    6747.9 50                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# run a linear model with main effects and interactions
lm.mod2 &amp;lt;- lm(breaks ~ wool*tension, data = warpbreaks)

# ...and type III sums of squares 
Anova(lm.mod2, type = &amp;quot;III&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Anova Table (Type III tests)
## 
## Response: breaks
##               Sum Sq Df  F value    Pr(&amp;gt;F)    
## (Intercept)  17866.8  1 149.2757 2.426e-16 ***
## wool          1200.5  1  10.0301 0.0026768 ** 
## tension       2468.5  2  10.3121 0.0001881 ***
## wool:tension  1002.8  2   4.1891 0.0210442 *  
## Residuals     5745.1 48                       
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;FYI&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;functions only shown as an example and not actually run.&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# this function runs type II sums of squares: 
Anova(lm.mod2, type = &amp;quot;II&amp;quot;)
# this function runs type I sums of squares: 
anova(lm.mod2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;span style=&#34;color:mediumblue&#34;&gt; &lt;strong&gt;A few comments on types of sums of squares:&lt;/strong&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As a reminder, the type of sums of squares used in statistical tests can impact the results and subsequent interpretation. Type I, sums of squares tests for statistical significance by adding one variable to the model at time (and hence is also called &amp;ldquo;sequential&amp;rdquo;). If there is any unbalance in the treatments, the type I sums of squares are dependent on the order variables are added to the model and hence is often not the best choice for many agricultural experiment. Type III sums of squares (also called &amp;ldquo;partial&amp;rdquo; or &amp;ldquo;marginal&amp;rdquo;) evaluates the statistical significance of variable or interaction, assuming that the other variables are in the model. This is a decent default option. The last option is Type II sums of squares, which is the best option when &lt;em&gt;you are sure there are no interactions between variables&lt;/em&gt;. If there is complete balance among treatments (each treatment is observed the same number of times with no missing data), then there is no need to concern yourself with these different types of sums of squares.&lt;/p&gt;
&lt;h4 id=&#34;compare-models&#34;&gt;Compare Models&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# conduct an F test comparing the models
anova(lm.mod1, lm.mod2)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Variance Table
## 
## Model 1: breaks ~ wool + tension
## Model 2: breaks ~ wool * tension
##   Res.Df    RSS Df Sum of Sq      F  Pr(&amp;gt;F)  
## 1     50 6747.9                              
## 2     48 5745.1  2    1002.8 4.1891 0.02104 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# also, consider doing a stepwise approach for finding the best model:
step(lm.mod2)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Start:  AIC=264.02
## breaks ~ wool * tension
## 
##                Df Sum of Sq    RSS    AIC
## &amp;lt;none&amp;gt;                      5745.1 264.02
## - wool:tension  2    1002.8 6747.9 268.71
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = breaks ~ wool * tension, data = warpbreaks)
## 
## Coefficients:
##    (Intercept)           woolB        tensionM        tensionH  woolB:tensionM  
##          44.56          -16.33          -20.56          -20.00           21.11  
## woolB:tensionH  
##          10.56
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;model-diagnostics&#34;&gt;Model diagnostics&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(lm.mod2) #this will produce 4 plots of residuals
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-12-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-12-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-12-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;shapiro.test(resid(lm.mod2)) #standard shapiro-wilk test. 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Shapiro-Wilk normality test
## 
## data:  resid(lm.mod2)
## W = 0.98686, p-value = 0.8162
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# this variable could be analyzed with a log-normal model instead
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;least-squares-means--contrasts&#34;&gt;Least squares means &amp;amp; contrasts&lt;/h4&gt;
&lt;p&gt;The emmeans package is a flexible package for extracting the estimated marginal means (in SAS, the &amp;ldquo;least squares means&amp;rdquo;) from different linear models. It is compatible with a large number of R linear modelling packages.&lt;/p&gt;
&lt;p&gt;Here is some code for extracting the marginal means and conducting contrasts.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# extract least squares means for &#39;tension&#39;
(lsm &amp;lt;- emmeans(lm.mod2, ~ tension))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NOTE: Results may be misleading due to involvement in interactions
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  tension emmean   SE df lower.CL upper.CL
##  L         36.4 2.58 48     31.2     41.6
##  M         26.4 2.58 48     21.2     31.6
##  H         21.7 2.58 48     16.5     26.9
## 
## Results are averaged over the levels of: wool 
## Confidence level used: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;emmeans(lm.mod2, &amp;quot;wool&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NOTE: Results may be misleading due to involvement in interactions
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  wool emmean   SE df lower.CL upper.CL
##  A      31.0 2.11 48     26.8     35.3
##  B      25.3 2.11 48     21.0     29.5
## 
## Results are averaged over the levels of: tension 
## Confidence level used: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All pairwise comparisons within each level of tension:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;contrast(lsm, &amp;quot;pairwise&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  contrast estimate   SE df t.ratio p.value
##  L - M       10.00 3.65 48   2.742  0.0229
##  L - H       14.72 3.65 48   4.037  0.0006
##  M - H        4.72 3.65 48   1.295  0.4049
## 
## Results are averaged over the levels of: wool 
## P value adjustment: tukey method for comparing a family of 3 estimates
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Conduct custom contrasts comparing &amp;lsquo;Low&amp;rsquo; tension versus &amp;lsquo;Medium&amp;rsquo; and &amp;lsquo;High&amp;rsquo; and &amp;lsquo;High&amp;rsquo; versus &amp;lsquo;Medium&amp;rsquo; and &amp;lsquo;Low&amp;rsquo;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# see the order of each level in a factor
levels(warpbreaks$tension)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;L&amp;quot; &amp;quot;M&amp;quot; &amp;quot;H&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# construct a list of constructs 
# each item must be same length as the the number of levels present in the variable tension
# use numbers and fracions to indicate the contrasting levels
# the numbers must sum to zero 
cList &amp;lt;- list(LvMH = c(1, -0.5, -0.5), # low vs high + medium
              HvLM = c(0.5, 0.5, -1))  # high vs low + medium

# check that each contrast sums to zero
lapply(cList, sum)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $LvMH
## [1] 0
## 
## $HvLM
## [1] 0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# perform custom contrast and include a Bonferroni adjustment
summary(contrast(lsm, cList, adjust = &amp;quot;bonferroni&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  contrast estimate   SE df t.ratio p.value
##  LvMH        12.36 3.16 48   3.914  0.0006
##  HvLM         9.72 3.16 48   3.078  0.0069
## 
## Results are averaged over the levels of: wool 
## P value adjustment: bonferroni method for 2 tests
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;randomised-complete-block-design-rcbd---fixed-effects-model&#34;&gt;Randomised Complete Block Design (RCBD) - fixed effects model&lt;/h4&gt;
&lt;p&gt;This example uses rapeseed yield data from multiple locations, years and cultivars. Within a single location or year, the replication is often balanced.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Load Data and examine:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(shafii.rapeseed) # from the &#39;agridat&#39; package

rapeseed1987 &amp;lt;- shafii.rapeseed %&amp;gt;% filter(year == 87) %&amp;gt;% 
  mutate(block = fct_drop(rep), Cv = fct_drop(gen), loc = fct_drop(loc))

str(rapeseed1987)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:	216 obs. of  7 variables:
##  $ year : int  87 87 87 87 87 87 87 87 87 87 ...
##  $ loc  : Factor w/ 9 levels &amp;quot;GGA&amp;quot;,&amp;quot;ID&amp;quot;,&amp;quot;MT&amp;quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ rep  : Factor w/ 4 levels &amp;quot;R1&amp;quot;,&amp;quot;R2&amp;quot;,&amp;quot;R3&amp;quot;,..: 1 2 3 4 1 2 3 4 1 2 ...
##  $ gen  : Factor w/ 6 levels &amp;quot;Bienvenu&amp;quot;,&amp;quot;Bridger&amp;quot;,..: 1 1 1 1 2 2 2 2 3 3 ...
##  $ yield: num  961 1329 1781 1698 1605 ...
##  $ block: Factor w/ 4 levels &amp;quot;R1&amp;quot;,&amp;quot;R2&amp;quot;,&amp;quot;R3&amp;quot;,..: 1 2 3 4 1 2 3 4 1 2 ...
##  $ Cv   : Factor w/ 6 levels &amp;quot;Bienvenu&amp;quot;,&amp;quot;Bridger&amp;quot;,..: 1 1 1 1 2 2 2 2 3 3 ...
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;count_na(rapeseed1987)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  year   loc   rep   gen yield block    Cv 
##     0     0     0     0     0     0     0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(rapeseed1987$Cv, rapeseed1987$loc) #experiment has 1 rep per block 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           
##            GGA ID MT NC OR SC TGA TX WA
##   Bienvenu   4  4  4  4  4  4   4  4  4
##   Bridger    4  4  4  4  4  4   4  4  4
##   Cascade    4  4  4  4  4  4   4  4  4
##   Dwarf      4  4  4  4  4  4   4  4  4
##   Glacier    4  4  4  4  4  4   4  4  4
##   Jet        4  4  4  4  4  4   4  4  4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hist(rapeseed1987$yield, col = &amp;quot;gold&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(yield ~ Cv, data = rapeseed1987, col = &amp;quot;orangered&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-16-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(yield ~ loc, data = rapeseed1987, col = &amp;quot;chartreuse&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-16-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Analyse experiment:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# for this example, the analysis will only be done for a single year
# block is nested within location
# if each block had a unique name, &#39;Error(block)&#39; would suffce
shaf.aov &amp;lt;- aov(yield ~ Cv*loc + Error(block), data = rapeseed1987)

summary(shaf.aov)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Error: block
##           Df Sum Sq Mean Sq F value Pr(&amp;gt;F)
## Residuals  3 336565  112188               
## 
## Error: Within
##            Df    Sum Sq  Mean Sq F value   Pr(&amp;gt;F)    
## Cv          5   3203992   640798   2.645 0.025111 *  
## loc         8 318197192 39774649 164.165  &amp;lt; 2e-16 ***
## Cv:loc     40  22707425   567686   2.343 0.000103 ***
## Residuals 159  38523267   242285                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;emmeans(shaf.aov, ~ Cv | loc)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Note: re-fitting model with sum-to-zero contrasts
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## loc = GGA:
##  Cv       emmean  SE  df lower.CL upper.CL
##  Bienvenu   1442 245 161      959     1926
##  Bridger    1363 245 161      880     1847
##  Cascade    1505 245 161     1021     1988
##  Dwarf      1295 245 161      811     1779
##  Glacier    1681 245 161     1197     2164
##  Jet        1091 245 161      607     1575
## 
## loc = ID:
##  Cv       emmean  SE  df lower.CL upper.CL
##  Bienvenu   1242 245 161      759     1726
##  Bridger     947 245 161      463     1430
##  Cascade     773 245 161      290     1257
##  Dwarf       932 245 161      448     1415
##  Glacier    1111 245 161      627     1595
##  Jet        1064 245 161      580     1548
## 
## loc = MT:
##  Cv       emmean  SE  df lower.CL upper.CL
##  Bienvenu   2616 245 161     2132     3100
##  Bridger    2828 245 161     2345     3312
##  Cascade    2916 245 161     2433     3400
##  Dwarf      3452 245 161     2968     3935
##  Glacier    3307 245 161     2823     3790
##  Jet        3660 245 161     3177     4144
## 
## loc = NC:
##  Cv       emmean  SE  df lower.CL upper.CL
##  Bienvenu   1001 245 161      517     1485
##  Bridger    1064 245 161      581     1548
##  Cascade     745 245 161      262     1229
##  Dwarf      1014 245 161      530     1497
##  Glacier    1229 245 161      746     1713
##  Jet        1674 245 161     1190     2157
## 
## loc = OR:
##  Cv       emmean  SE  df lower.CL upper.CL
##  Bienvenu   4556 245 161     4072     5039
##  Bridger    2530 245 161     2046     3013
##  Cascade    3336 245 161     2852     3819
##  Dwarf      3932 245 161     3448     4415
##  Glacier    4185 245 161     3702     4669
##  Jet        3220 245 161     2736     3703
## 
## loc = SC:
##  Cv       emmean  SE  df lower.CL upper.CL
##  Bienvenu   2500 245 161     2016     2983
##  Bridger    2705 245 161     2221     3189
##  Cascade    2119 245 161     1635     2602
##  Dwarf      1894 245 161     1410     2377
##  Glacier    2717 245 161     2234     3201
##  Jet        2833 245 161     2349     3316
## 
## loc = TGA:
##  Cv       emmean  SE  df lower.CL upper.CL
##  Bienvenu   1258 245 161      774     1741
##  Bridger    1868 245 161     1384     2351
##  Cascade    1708 245 161     1224     2191
##  Dwarf       873 245 161      389     1356
##  Glacier    1453 245 161      970     1937
##  Jet         954 245 161      470     1438
## 
## loc = TX:
##  Cv       emmean  SE  df lower.CL upper.CL
##  Bienvenu    838 245 161      354     1322
##  Bridger    1069 245 161      585     1553
##  Cascade     735 245 161      251     1218
##  Dwarf       988 245 161      505     1472
##  Glacier     952 245 161      468     1435
##  Jet        1408 245 161      925     1892
## 
## loc = WA:
##  Cv       emmean  SE  df lower.CL upper.CL
##  Bienvenu   4375 245 161     3891     4859
##  Bridger    4604 245 161     4120     5087
##  Cascade    4464 245 161     3981     4948
##  Dwarf      3974 245 161     3490     4458
##  Glacier    4740 245 161     4256     5224
##  Jet        4344 245 161     3861     4828
## 
## Warning: EMMs are biased unless design is perfectly balanced 
## Confidence level used: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;anova-for-mixed-models&#34;&gt;ANOVA for mixed models&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;(models with random and fixed effects)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Random effects are often those treatments levels drawn from a large population of possible treatment levels and there is interest in understanding the distribution and variance of that population. This in contrast to fixed effects, where the inferences are restricted to the treatment levels tested.&lt;/p&gt;
&lt;p&gt;Blocking factors and Year are often considered random factors because a researcher is not interested in particular years or a blocking factor. When there is unbalanced replication, the variance components should be estimated with maximum likelihood or REML, which implies use of the packages &amp;ldquo;lmer&amp;rdquo; and/or &amp;ldquo;nlme&amp;rdquo;.&lt;/p&gt;
&lt;h4 id=&#34;randomised-complete-block-design-rcbd---mixed-effects&#34;&gt;Randomised Complete Block Design (RCBD) - mixed effects&lt;/h4&gt;
&lt;p&gt;The &amp;ldquo;shafii.rapeseed&amp;rdquo; data set will be used for this section.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Analyse experiment using a mixed model:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This uses the function &lt;code&gt;lme()&lt;/code&gt; from the package &amp;ldquo;nlme&amp;rdquo;. Functionally, it is very similar to calling &lt;code&gt;lme4::lmer()&lt;/code&gt;. The degrees of freedom are different (&lt;code&gt;lmer()&lt;/code&gt; is using Satterthwaite&amp;rsquo;s approximation), but the p-values are the same.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# turn year into the factor &amp;quot;Year&amp;quot;
shafii.rapeseed$Year &amp;lt;- as.factor(shafii.rapeseed$year)
# create a blocking variable that is unique for each location-by-year combination
# so R doesn&#39;t conflate &amp;quot;R1&amp;quot; from one location/year with another location/year
shafii.rapeseed$Rep &amp;lt;- as.factor(paste(shafii.rapeseed$loc, shafii.rapeseed$year, shafii.rapeseed$rep, sep = &amp;quot;_&amp;quot;))

shaf.lme &amp;lt;- lme(fixed = yield ~ gen*loc + Year,
                  random = ~ 1|Rep,
                  data = shafii.rapeseed, method = &amp;quot;REML&amp;quot;)

# view sum of squares table 
# when anova() is called for an lme object, the function called is actually anova.lme()
anova(shaf.lme, type = &amp;quot;marginal&amp;quot;) # &amp;quot;marginal&amp;quot; is equivalent to type III sums of squares
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             numDF denDF   F-value p-value
## (Intercept)     1   470 16.204597  0.0001
## gen             5   470  1.092341  0.3637
## loc            13    92 13.074492  &amp;lt;.0001
## Year            2    92  2.035054  0.1365
## gen:loc        65   470  2.575753  &amp;lt;.0001
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Anova(shaf.lme, type = &amp;quot;3&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Deviance Table (Type III tests)
## 
## Response: yield
##                Chisq Df Pr(&amp;gt;Chisq)    
## (Intercept)  16.2046  1  5.686e-05 ***
## gen           5.4617  5     0.3622    
## loc         169.9684 13  &amp;lt; 2.2e-16 ***
## Year          4.0701  2     0.1307    
## gen:loc     167.4239 65  5.579e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# FYI: use &amp;quot;anova(model.lme)&amp;quot; for type I sums of squares

# lmer notation
shaf.lmer &amp;lt;- lmer(yield ~ gen*loc + Year + (1|Rep),
                  data = shafii.rapeseed, REML = T)
anova(shaf.lmer, type = &amp;quot;marginal&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Marginal Analysis of Variance Table with Satterthwaite&#39;s method
##           Sum Sq Mean Sq NumDF  DenDF F value    Pr(&amp;gt;F)    
## gen      1860586  372117     5 470.00  1.0923    0.3637    
## loc     57901484 4453960    13 159.37 13.0745 &amp;lt; 2.2e-16 ***
## Year     1386524  693262     2  92.00  2.0351    0.1365    
## gen:loc 57034691  877457    65 470.00  2.5758 5.499e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Anova(shaf.lmer, type = &amp;quot;3&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Deviance Table (Type III Wald chisquare tests)
## 
## Response: yield
##                Chisq Df Pr(&amp;gt;Chisq)    
## (Intercept)  16.2046  1  5.686e-05 ***
## gen           5.4617  5     0.3622    
## loc         169.9684 13  &amp;lt; 2.2e-16 ***
## Year          4.0701  2     0.1307    
## gen:loc     167.4239 65  5.579e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;diagnostics-model-building&#34;&gt;Diagnostics, model building&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(shaf.lme)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;qqnorm(shaf.lme, abline = c(0, 1))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-19-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;least-squares-means&#34;&gt;Least squares means&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# for cultivar 
(lme.means.cv &amp;lt;- emmeans(shaf.lme, &amp;quot;gen&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NOTE: Results may be misleading due to involvement in interactions
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  gen      emmean  SE df lower.CL upper.CL
##  Bienvenu   2432 112 92     2211     2654
##  Bridger    2314 112 92     2092     2536
##  Cascade    2184 112 92     1962     2406
##  Dwarf      2308 112 92     2087     2530
##  Glacier    2463 112 92     2242     2685
##  Jet        2304 112 92     2082     2525
## 
## Results are averaged over the levels of: loc, Year 
## Degrees-of-freedom method: containment 
## Confidence level used: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# for location
(lme.means.loc &amp;lt;- emmeans(shaf.lme, &amp;quot;loc&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NOTE: Results may be misleading due to involvement in interactions
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  loc emmean  SE df lower.CL upper.CL
##  GGA   1682 329 92     1030     2335
##  ID    4217 261 92     3698     4736
##  KS    1120 476 92      174     2066
##  MS    2204 476 92     1258     3150
##  MT    3339 474 92     2398     4280
##  NC    1328 329 92      676     1981
##  NY    3139 476 92     2193     4085
##  OR    3292 329 92     2640     3945
##  SC    1819 261 92     1300     2338
##  TGA   1028 261 92      509     1547
##  TN    2543 476 92     1597     3490
##  TX     827 329 92      174     1479
##  VA    2282 328 92     1631     2932
##  WA    3861 261 92     3342     4380
## 
## Results are averaged over the levels of: gen, Year 
## Degrees-of-freedom method: containment 
## Confidence level used: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# for cultivar means within each location
lme.means.int &amp;lt;- emmeans(shaf.lme, ~ gen | loc + Year)

# this code would produce location means within each cultivar 
# emmeans(model.lme, ~ loc | gen))
# also: 
# emmeans(model.lme, ~ loc | gen)) provides the same estimates as &#39;emmeans(model.lme, ~ gen | loc))&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;pairwise-contrasts&#34;&gt;Pairwise Contrasts:&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# all pairwise
pairs(lme.means.cv)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  contrast           estimate   SE  df t.ratio p.value
##  Bienvenu - Bridger   118.57 87.6 470   1.353  0.7548
##  Bienvenu - Cascade   248.34 87.6 470   2.834  0.0539
##  Bienvenu - Dwarf     124.11 87.6 470   1.417  0.7170
##  Bienvenu - Glacier   -31.00 87.6 470  -0.354  0.9993
##  Bienvenu - Jet       128.70 87.6 470   1.469  0.6843
##  Bridger - Cascade    129.77 87.6 470   1.481  0.6765
##  Bridger - Dwarf        5.54 87.6 470   0.063  1.0000
##  Bridger - Glacier   -149.57 87.6 470  -1.707  0.5277
##  Bridger - Jet         10.13 87.6 470   0.116  1.0000
##  Cascade - Dwarf     -124.23 87.6 470  -1.418  0.7161
##  Cascade - Glacier   -279.34 87.6 470  -3.188  0.0190
##  Cascade - Jet       -119.64 87.6 470  -1.366  0.7477
##  Dwarf - Glacier     -155.10 87.6 470  -1.770  0.4861
##  Dwarf - Jet            4.59 87.6 470   0.052  1.0000
##  Glacier - Jet        159.70 87.6 470   1.823  0.4521
## 
## Results are averaged over the levels of: loc, Year 
## Degrees-of-freedom method: containment 
## P value adjustment: tukey method for comparing a family of 6 estimates
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# plot results
plot(lme.means.cv, comparison = T)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(lme.means.loc, comparison = T, horizontal = F) # rotate plots to vertical position
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Comparison discrepancy in group &amp;quot;1&amp;quot;, GGA - OR:
##     Target overlap = 0.0083, overlap on graph = -0.0111
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-22-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# blue bars = lsmeans confidence 95% confidence intervals
# red arrows. pairwise differences (overlapping arrows = not significantly different)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For those who want the letters assigned to treatments based on all pairwise comparisons, it&amp;rsquo;s an unwieldy road:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(multcomp) # this will need to be installed if you do not already have it
tukey &amp;lt;- glht(shaf.lme, linfct = mcp(loc = &amp;quot;Tukey&amp;quot;))
### extract information
cld_tukey &amp;lt;- cld(tukey)
print(cld_tukey)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  GGA   ID   KS   MS   MT   NC   NY   OR   SC  TGA   TN   TX   VA   WA 
##  &amp;quot;a&amp;quot;  &amp;quot;b&amp;quot;  &amp;quot;a&amp;quot; &amp;quot;ac&amp;quot; &amp;quot;ab&amp;quot;  &amp;quot;a&amp;quot; &amp;quot;ab&amp;quot; &amp;quot;bc&amp;quot;  &amp;quot;a&amp;quot;  &amp;quot;a&amp;quot; &amp;quot;ab&amp;quot;  &amp;quot;a&amp;quot;  &amp;quot;a&amp;quot; &amp;quot;bc&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Interaction plots can also be done:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(but, it gets unwieldy)&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(lme.means.int, comparison = T, adjust = &amp;quot;tukey&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;other-pre-set-contrasts&#34;&gt;Other pre-set contrasts&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# compare to a control, e.g. &amp;quot;Bridger&amp;quot;
levels(shafii.rapeseed$gen)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Bienvenu&amp;quot; &amp;quot;Bridger&amp;quot;  &amp;quot;Cascade&amp;quot;  &amp;quot;Dwarf&amp;quot;    &amp;quot;Glacier&amp;quot;  &amp;quot;Jet&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Bridger is listed in position 2 of the factor &#39;shafii.rapeseed$gen&#39;
# so &#39;2&#39; is set as the reference level in the following contrast statement: 

# &amp;quot;trt.vs.ctrlk&amp;quot; (treatment versus control treatment k) is a specific option to compare all treatment levels to a user-defined level
# by default, it will use the last level as the reference level

contrast(lme.means.cv, &amp;quot;trt.vs.ctrlk&amp;quot;, ref = 2) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  contrast           estimate   SE  df t.ratio p.value
##  Bienvenu - Bridger   118.57 87.6 470   1.353  0.5118
##  Cascade - Bridger   -129.77 87.6 470  -1.481  0.4315
##  Dwarf - Bridger       -5.54 87.6 470  -0.063  0.9998
##  Glacier - Bridger    149.57 87.6 470   1.707  0.3034
##  Jet - Bridger        -10.13 87.6 470  -0.116  0.9990
## 
## Results are averaged over the levels of: loc, Year 
## Degrees-of-freedom method: containment 
## P value adjustment: dunnettx method for 5 tests
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Search &lt;code&gt;?contrast.emmGrid&lt;/code&gt; to see full list of options for preset contrasts.&lt;/p&gt;
&lt;h4 id=&#34;custom-contrasts&#34;&gt;Custom contrasts&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# example: contrast Western locations versus Southern locations

# first, find out what levels are present
unique(shafii.rapeseed$loc)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] GGA ID  KS  MS  MT  NC  NY  OR  SC  TGA TN  TX  VA  WA 
## Levels: GGA ID KS MS MT NC NY OR SC TGA TN TX VA WA
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# next create a contrast list 
# this is a list of coefficients as long your list of treatment levels
# indicating what coefficients to give each treatment level

# in this example, levels &amp;quot;ID&amp;quot;, &amp;quot;MT&amp;quot;, &amp;quot;OR&amp;quot;, and &amp;quot;WA&amp;quot; are contrasted versus
# &amp;quot;NC&amp;quot;, &amp;quot;SC&amp;quot;, &amp;quot;MS&amp;quot;, &amp;quot;TN&amp;quot;, &amp;quot;TX&amp;quot; and &amp;quot;VA&amp;quot;

cList &amp;lt;- list(West_V_South = c(0, 1/4, 0, -1/6, 1/4, -1/6, 0, 1/4, -1/6, 0, -1/6, -1/6, -1/6, 1/4))

# check that each contrast sums to zero:
lapply(cList, sum)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $West_V_South
## [1] 5.551115e-17
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lme.means.loc2 &amp;lt;- emmeans(shaf.lme, &amp;quot;loc&amp;quot;, contr = cList)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NOTE: Results may be misleading due to involvement in interactions
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(lme.means.loc2)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $emmeans
##  loc emmean  SE df lower.CL upper.CL
##  GGA   1682 329 92     1030     2335
##  ID    4217 261 92     3698     4736
##  KS    1120 476 92      174     2066
##  MS    2204 476 92     1258     3150
##  MT    3339 474 92     2398     4280
##  NC    1328 329 92      676     1981
##  NY    3139 476 92     2193     4085
##  OR    3292 329 92     2640     3945
##  SC    1819 261 92     1300     2338
##  TGA   1028 261 92      509     1547
##  TN    2543 476 92     1597     3490
##  TX     827 329 92      174     1479
##  VA    2282 328 92     1631     2932
##  WA    3861 261 92     3342     4380
## 
## Results are averaged over the levels of: gen, Year 
## Degrees-of-freedom method: containment 
## Confidence level used: 0.95 
## 
## $contrasts
##  contrast     estimate  SE df t.ratio p.value
##  West_V_South     1843 233 92   7.910  &amp;lt;.0001
## 
## Results are averaged over the levels of: gen, Year 
## Degrees-of-freedom method: containment
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# same contrast can also be done within each level of &#39;gen&#39;:
emmeans(shaf.lme, ~ loc | gen, contr = cList)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $emmeans
## gen = Bienvenu:
##  loc emmean  SE df lower.CL upper.CL
##  GGA   1785 379 92  1032.31     2537
##  ID    4742 303 92  4140.13     5345
##  KS    1179 546 92    94.60     2263
##  MS    2455 546 92  1371.47     3539
##  MT    2825 544 92  1745.38     3904
##  NC    1330 379 92   577.36     2082
##  NY    2934 546 92  1849.69     4018
##  OR    4118 379 92  3365.98     4870
##  SC    1844 303 92  1241.42     2446
##  TGA    893 303 92   290.99     1496
##  TN    2965 546 92  1880.59     4049
##  TX     919 379 92   167.04     1671
##  VA    2124 378 92  1373.34     2875
##  WA    3943 303 92  3340.44     4545
## 
## gen = Bridger:
##  loc emmean  SE df lower.CL upper.CL
##  GGA   1470 379 92   718.17     2223
##  ID    3591 303 92  2989.15     4194
##  KS    1091 546 92     7.35     2175
##  MS    2478 546 92  1393.89     3562
##  MT    3037 544 92  1957.63     4117
##  NC    1479 379 92   727.28     2232
##  NY    3130 546 92  2045.60     4214
##  OR    2564 379 92  1811.99     3316
##  SC    2282 303 92  1679.58     2884
##  TGA   1603 303 92  1000.66     2205
##  TN    2485 546 92  1401.33     3569
##  TX     851 379 92    99.08     1604
##  VA    2397 378 92  1646.76     3148
##  WA    3935 303 92  3332.27     4537
## 
## gen = Cascade:
##  loc emmean  SE df lower.CL upper.CL
##  GGA   1758 379 92  1006.25     2511
##  ID    4081 303 92  3479.04     4684
##  KS     891 546 92  -193.40     1975
##  MS    1598 546 92   514.04     2682
##  MT    3125 544 92  2045.63     4205
##  NC    1062 379 92   309.61     1814
##  NY    2586 546 92  1502.21     3670
##  OR    2806 379 92  2053.82     3558
##  SC    1982 303 92  1379.70     2584
##  TGA   1492 303 92   889.83     2094
##  TN    2006 546 92   922.37     3090
##  TX     796 379 92    43.59     1548
##  VA    2191 378 92  1440.56     2942
##  WA    4203 303 92  3600.69     4805
## 
## gen = Dwarf:
##  loc emmean  SE df lower.CL upper.CL
##  GGA   1538 379 92   785.71     2290
##  ID    4326 303 92  3723.81     4928
##  KS    1208 546 92   123.85     2292
##  MS    1966 546 92   881.69     3050
##  MT    3661 544 92  2581.14     4740
##  NC    1321 379 92   568.53     2073
##  NY    3645 546 92  2561.26     4729
##  OR    3594 379 92  2841.40     4346
##  SC    1292 303 92   690.10     1895
##  TGA    451 303 92  -151.81     1053
##  TN    2688 546 92  1603.57     3771
##  TX     654 379 92   -98.64     1406
##  VA    2250 378 92  1499.12     3000
##  WA    3726 303 92  3123.52     4328
## 
## gen = Glacier:
##  loc emmean  SE df lower.CL upper.CL
##  GGA   2031 379 92  1278.35     2783
##  ID    4299 303 92  3696.61     4901
##  KS    1268 546 92   183.85     2352
##  MS    2861 546 92  1776.82     3945
##  MT    3516 544 92  2436.14     4595
##  NC    1452 379 92   699.82     2204
##  NY    3301 546 92  2217.49     4385
##  OR    3472 379 92  2719.36     4224
##  SC    2025 303 92  1422.97     2628
##  TGA   1109 303 92   506.90     1712
##  TN    2265 546 92  1180.58     3348
##  TX     720 379 92   -31.85     1473
##  VA    2363 378 92  1612.64     3114
##  WA    3807 303 92  3205.02     4410
## 
## gen = Jet:
##  loc emmean  SE df lower.CL upper.CL
##  GGA   1511 379 92   758.95     2263
##  ID    4262 303 92  3659.68     4864
##  KS    1082 546 92    -2.40     2166
##  MS    1866 546 92   781.68     2950
##  MT    3869 544 92  2789.89     4949
##  NC    1326 379 92   573.58     2078
##  NY    3237 546 92  2152.80     4321
##  OR    3199 379 92  2446.70     3951
##  SC    1488 303 92   886.13     2091
##  TGA    622 303 92    19.27     1224
##  TN    2853 546 92  1768.63     3937
##  TX    1020 379 92   267.99     1772
##  VA    2364 378 92  1613.85     3115
##  WA    3554 303 92  2952.19     4157
## 
## Results are averaged over the levels of: Year 
## Degrees-of-freedom method: containment 
## Confidence level used: 0.95 
## 
## $contrasts
## gen = Bienvenu:
##  contrast     estimate  SE df t.ratio p.value
##  West_V_South     1968 267 92   7.359  &amp;lt;.0001
## 
## gen = Bridger:
##  contrast     estimate  SE df t.ratio p.value
##  West_V_South     1286 267 92   4.811  &amp;lt;.0001
## 
## gen = Cascade:
##  contrast     estimate  SE df t.ratio p.value
##  West_V_South     1948 267 92   7.286  &amp;lt;.0001
## 
## gen = Dwarf:
##  contrast     estimate  SE df t.ratio p.value
##  West_V_South     2132 267 92   7.972  &amp;lt;.0001
## 
## gen = Glacier:
##  contrast     estimate  SE df t.ratio p.value
##  West_V_South     1826 267 92   6.828  &amp;lt;.0001
## 
## gen = Jet:
##  contrast     estimate  SE df t.ratio p.value
##  West_V_South     1902 267 92   7.112  &amp;lt;.0001
## 
## Results are averaged over the levels of: Year 
## Degrees-of-freedom method: containment
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To perform custom contrasts on a another variable, a cList and emmeans call for that variable is required.&lt;/p&gt;
&lt;h3 id=&#34;ancova&#34;&gt;ANCOVA&lt;/h3&gt;
&lt;p&gt;(analysis of covariance)
From a R programming perspective, this is no different than running a standard linear model. A data set from &lt;strong&gt;agridat&lt;/strong&gt;, &amp;ldquo;theobald.covariate&amp;rdquo; comparing corn silage yields across multiple years, locations and cultivars. The data set includes a covariate, &amp;ldquo;chu&amp;rdquo; (corn heat units, a bit like growing degree days).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Load data and examine:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(theobald.covariate)
str(theobald.covariate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &#39;data.frame&#39;:	256 obs. of  5 variables:
##  $ year : int  1990 1990 1990 1990 1990 1991 1991 1991 1991 1991 ...
##  $ env  : Factor w/ 7 levels &amp;quot;E1&amp;quot;,&amp;quot;E2&amp;quot;,&amp;quot;E3&amp;quot;,..: 1 2 3 4 7 1 2 3 4 5 ...
##  $ gen  : Factor w/ 10 levels &amp;quot;G01&amp;quot;,&amp;quot;G02&amp;quot;,&amp;quot;G03&amp;quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ yield: num  6.27 5.57 8.45 7.35 6.5 6.71 5.59 8.36 7.25 8.09 ...
##  $ chu  : num  2.57 2.53 2.72 2.72 2.48 2.44 2.55 2.75 2.75 2.61 ...
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;count_na(theobald.covariate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  year   env   gen yield   chu 
##     0     0     0     0     0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Exploratory plots:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# distributions of continuous variables
hist(theobald.covariate$yield, col = &amp;quot;gold&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hist(theobald.covariate$chu, col = &amp;quot;gray70&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-28-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# relationship between reponse variable and covariate:
with(theobald.covariate, plot(chu, yield))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-28-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;length(unique(theobald.covariate$chu))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 21
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# the usual boxplots: 
boxplot(yield ~ env, data = theobald.covariate, col = &amp;quot;orangered&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-28-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(yield ~ year, data = theobald.covariate, col = &amp;quot;chartreuse&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-28-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(yield ~ gen, data = theobald.covariate, col = &amp;quot;darkcyan&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-28-6.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Check the extent of replication:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;theobald.covariate$Year &amp;lt;- as.factor(theobald.covariate$year)
replications(yield ~ Year + env + gen, data = theobald.covariate)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $Year
## Year
## 1990 1991 1992 1993 1994 
##   40   63   60   45   48 
## 
## $env
## env
## E1 E2 E3 E4 E5 E6 E7 
## 35 35 44 36 36 36 34 
## 
## $gen
## gen
## G01 G02 G03 G04 G05 G06 G07 G08 G09 G10 
##  29  29  29  29  22  29  23  18  24  24
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# with(theobald.covariate, table(gen, env, Year)) # lots of useful output
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The treatments are not fully crossed, so a fully specified model of the form &lt;code&gt;yield ~  Year*env*gen*chu&lt;/code&gt; cannot be tested. The treatments and interactions were tested in reduced models and compared (not shown). The final &amp;ldquo;best&amp;rdquo; model is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# the covariate, chu, is added in like any other effect. 
theobald.lm2 &amp;lt;- lm(yield ~  Year + env*chu, data = theobald.covariate)
Anova(theobald.lm2, type = &amp;quot;III&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Anova Table (Type III tests)
## 
## Response: yield
##              Sum Sq  Df F value    Pr(&amp;gt;F)    
## (Intercept)   4.309   1  6.8321  0.009524 ** 
## Year         76.589   4 30.3607 &amp;lt; 2.2e-16 ***
## env          13.473   6  3.5607  0.002138 ** 
## chu          11.831   1 18.7596 2.187e-05 ***
## env:chu      13.376   6  3.5350  0.002268 ** 
## Residuals   150.096 238                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# how to extract the covariate slope(s): 
emtrends(theobald.lm2, ~ env, &amp;quot;chu&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  env chu.trend   SE  df lower.CL upper.CL
##  E1      7.015 1.62 238     3.82    10.21
##  E2      0.979 4.44 238    -7.76     9.72
##  E3      4.099 3.15 238    -2.11    10.31
##  E4     -2.884 3.54 238    -9.87     4.10
##  E5      8.222 2.70 238     2.90    13.54
##  E6      3.425 2.72 238    -1.93     8.78
##  E7     -0.359 2.55 238    -5.38     4.66
## 
## Results are averaged over the levels of: Year 
## Confidence level used: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# emmeans extracted as usual:
emmeans(theobald.lm2, ~ env)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NOTE: Results may be misleading due to involvement in interactions
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  env emmean    SE  df lower.CL upper.CL
##  E1    6.67 0.175 238     6.32     7.01
##  E2    5.13 0.256 238     4.63     5.64
##  E3    6.66 0.482 238     5.71     7.61
##  E4    7.22 0.508 238     6.22     8.22
##  E5    6.61 0.138 238     6.34     6.88
##  E6    6.43 0.236 238     5.97     6.90
##  E7    6.32 0.397 238     5.54     7.10
## 
## Results are averaged over the levels of: Year 
## Confidence level used: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;emmeans(theobald.lm2, ~ Year)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Year emmean    SE  df lower.CL upper.CL
##  1990   6.97 0.189 238     6.60     7.34
##  1991   6.75 0.170 238     6.41     7.08
##  1992   7.07 0.187 238     6.70     7.44
##  1993   5.39 0.208 238     4.98     5.80
##  1994   6.00 0.218 238     5.57     6.43
## 
## Results are averaged over the levels of: env 
## Confidence level used: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;split-plot&#34;&gt;Split-plot&lt;/h4&gt;
&lt;p&gt;Load &amp;ldquo;Oats&amp;rdquo; from nlme. Nitrogen level (&amp;ldquo;nitro&amp;rdquo;) is the main plot, cultivar (&amp;ldquo;Variety&amp;rdquo;) is the sub-plot and &amp;ldquo;Block&amp;rdquo; describes the blocking layout.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;data(Oats) 
str(Oats)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &#39;nfnGroupedData&#39;, &#39;nfGroupedData&#39;, &#39;groupedData&#39; and &#39;data.frame&#39;:	72 obs. of  4 variables:
##  $ Block  : Ord.factor w/ 6 levels &amp;quot;VI&amp;quot;&amp;lt;&amp;quot;V&amp;quot;&amp;lt;&amp;quot;III&amp;quot;&amp;lt;..: 6 6 6 6 6 6 6 6 6 6 ...
##  $ Variety: Factor w/ 3 levels &amp;quot;Golden Rain&amp;quot;,..: 3 3 3 3 1 1 1 1 2 2 ...
##  $ nitro  : num  0 0.2 0.4 0.6 0 0.2 0.4 0.6 0 0.2 ...
##  $ yield  : num  111 130 157 174 117 114 161 141 105 140 ...
##  - attr(*, &amp;quot;formula&amp;quot;)=Class &#39;formula&#39;  language yield ~ nitro | Block
##   .. ..- attr(*, &amp;quot;.Environment&amp;quot;)=&amp;lt;environment: R_GlobalEnv&amp;gt; 
##  - attr(*, &amp;quot;labels&amp;quot;)=List of 2
##   ..$ y: chr &amp;quot;Yield&amp;quot;
##   ..$ x: chr &amp;quot;Nitrogen concentration&amp;quot;
##  - attr(*, &amp;quot;units&amp;quot;)=List of 2
##   ..$ y: chr &amp;quot;(bushels/acre)&amp;quot;
##   ..$ x: chr &amp;quot;(cwt/acre)&amp;quot;
##  - attr(*, &amp;quot;inner&amp;quot;)=Class &#39;formula&#39;  language ~Variety
##   .. ..- attr(*, &amp;quot;.Environment&amp;quot;)=&amp;lt;environment: R_GlobalEnv&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;count_na(Oats)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Block Variety   nitro   yield 
##       0       0       0       0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Oats$N &amp;lt;- as.factor(Oats$nitro)
replications(yield ~ Variety*N*Block, data = Oats)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         Variety               N           Block       Variety:N   Variety:Block 
##              24              18              12               6               4 
##         N:Block Variety:N:Block 
##               3               1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(Oats$Variety, Oats$N)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              
##               0 0.2 0.4 0.6
##   Golden Rain 6   6   6   6
##   Marvellous  6   6   6   6
##   Victory     6   6   6   6
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;hist(Oats$yield, col = &amp;quot;gold&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(yield ~ N, data = Oats, col = &amp;quot;dodgerblue1&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-31-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;boxplot(yield ~ Variety, data = Oats, col = &amp;quot;red3&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/anova-in-r/index_files/figure-html/unnamed-chunk-31-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Balanced Trial Analysis&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The format for specifying split-plot error terms is &lt;code&gt;Error(blocking factor/main plot)&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#contrasts(&amp;quot;contr.sum&amp;quot;)
spl.oats &amp;lt;- aov(yield ~ Variety*N + Error(Block:N), data = Oats) 
summary(spl.oats)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Error: Block:N
##           Df Sum Sq Mean Sq F value  Pr(&amp;gt;F)   
## N          3  20020    6673   7.556 0.00143 **
## Residuals 20  17663     883                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Error: Within
##           Df Sum Sq Mean Sq F value Pr(&amp;gt;F)  
## Variety    2   1786   893.2   2.930 0.0649 .
## Variety:N  6    322    53.6   0.176 0.9818  
## Residuals 40  12194   304.8                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;emmeans(spl.oats, &amp;quot;N&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Note: re-fitting model with sum-to-zero contrasts
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NOTE: Results may be misleading due to involvement in interactions
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  N   emmean SE df lower.CL upper.CL
##  0     79.4  7 20     64.8       94
##  0.2   98.9  7 20     84.3      114
##  0.4  114.2  7 20     99.6      129
##  0.6  123.4  7 20    108.8      138
## 
## Results are averaged over the levels of: Variety 
## Warning: EMMs are biased unless design is perfectly balanced 
## Confidence level used: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;emmeans(spl.oats, ~ Variety) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Note: re-fitting model with sum-to-zero contrasts
## NOTE: Results may be misleading due to involvement in interactions
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Variety     emmean   SE   df lower.CL upper.CL
##  Golden Rain  104.5 4.55 46.1     95.3      114
##  Marvellous   109.8 4.55 46.1    100.6      119
##  Victory       97.6 4.55 46.1     88.5      107
## 
## Results are averaged over the levels of: N 
## Warning: EMMs are biased unless design is perfectly balanced 
## Confidence level used: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Unbalanced Trial Analysis&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spl.oats2 &amp;lt;- lmer(yield ~ N*Variety + (1|Block:N), data = Oats) 
Anova(spl.oats2, type = &amp;quot;3&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Analysis of Deviance Table (Type III Wald chisquare tests)
## 
## Response: yield
##               Chisq Df Pr(&amp;gt;Chisq)    
## (Intercept) 77.1670  1  &amp;lt; 2.2e-16 ***
## N           13.9028  3   0.003041 ** 
## Variety      2.2747  2   0.320663    
## N:Variety    1.0554  6   0.983423    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;emmeans(spl.oats2, &amp;quot;N&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NOTE: Results may be misleading due to involvement in interactions
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  N   emmean SE df lower.CL upper.CL
##  0     79.4  7 20     64.8       94
##  0.2   98.9  7 20     84.3      114
##  0.4  114.2  7 20     99.6      129
##  0.6  123.4  7 20    108.8      138
## 
## Results are averaged over the levels of: Variety 
## Degrees-of-freedom method: kenward-roger 
## Confidence level used: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;emmeans(spl.oats2, ~ Variety) 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NOTE: Results may be misleading due to involvement in interactions
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Variety     emmean   SE   df lower.CL upper.CL
##  Golden Rain  104.5 4.55 46.1     95.3      114
##  Marvellous   109.8 4.55 46.1    100.6      119
##  Victory       97.6 4.55 46.1     88.5      107
## 
## Results are averaged over the levels of: N 
## Degrees-of-freedom method: kenward-roger 
## Confidence level used: 0.95
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;other-designs&#34;&gt;Other Designs&lt;/h3&gt;
&lt;p&gt;There are many other experimental designs commonly used in agricultural trials (split-split plot, split-block, alpha lattice, etc). We have written an online resource for routine incorporation of spatial covariates into field trial analysis that includes information on how to &lt;a href=&#34;https://idahoagstats.github.io/guide-to-field-trial-spatial-analysis/model-extension-r.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;analyze different designs&lt;/a&gt;. You could also consider using the &lt;a href=&#34;https://CRAN.R-project.org/package=agricolae&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;agricolae&lt;/a&gt; package.&lt;/p&gt;
&lt;h3 id=&#34;extra-functions&#34;&gt;Extra Functions&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;for extracting model parameters, diagnostics and other model information&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;These work differently with different R object types. That is, different output will result depending on if a &amp;ldquo;lm&amp;rdquo;, &amp;ldquo;lme&amp;rdquo; or &amp;ldquo;merMod&amp;rdquo; (lmer) object is used in the function call.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# extract model summary
summary()

#extract coefficients:
coef()

#extract residuals
resid()
rstudent()
residuals()

# extract predicted values
fits()

# make diagnostic plots
plot()

# extract influence measures:
influence.measures()

#other fir diagnostics:
cooks.distance()
dffits()
dfbeta()
hat()

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To see the all functions available for a particular type of linear model object, use:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;methods(class = &amp;quot;lm&amp;quot;) # for lm objects
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] add1                addterm             alias              
##  [4] anova               Anova               attrassign         
##  [7] avPlot              Boot                bootCase           
## [10] boxcox              boxCox              brief              
## [13] case.names          ceresPlot           coerce             
## [16] concordance         confidenceEllipse   confint            
## [19] Confint             cooks.distance      crPlot             
## [22] deltaMethod         deviance            dfbeta             
## [25] dfbetaPlots         dfbetas             dfbetasPlots       
## [28] drop1               dropterm            dummy.coef         
## [31] durbinWatsonTest    effects             emm_basis          
## [34] extractAIC          family              formula            
## [37] hatvalues           hccm                infIndexPlot       
## [40] influence           influencePlot       initialize         
## [43] inverseResponsePlot kappa               labels             
## [46] leveneTest          leveragePlot        linearHypothesis   
## [49] logLik              logtrans            mcPlot             
## [52] mmp                 model.frame         model.matrix       
## [55] ncvTest             nextBoot            nobs               
## [58] outlierTest         plot                powerTransform     
## [61] predict             Predict             print              
## [64] proj                qqnorm              qqPlot             
## [67] qr                  recover_data        residualPlot       
## [70] residualPlots       residuals           rstandard          
## [73] rstudent            S                   show               
## [76] sigmaHat            simulate            slotsFromS3        
## [79] spreadLevelPlot     summary             symbox             
## [82] variable.names      vcov               
## see &#39;?methods&#39; for accessing help and source code
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;methods(class = &amp;quot;lme&amp;quot;) # for lme4 objects
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] ACF              anova            Anova            augPred         
##  [5] coef             comparePred      confint          Confint         
##  [9] deltaMethod      deviance         emm_basis        extractAIC      
## [13] fitted           fixef            formula          getData         
## [17] getGroups        getGroupsFormula getResponse      getVarCov       
## [21] influence        intervals        linearHypothesis logLik          
## [25] matchCoefs       nobs             pairs            plot            
## [29] predict          print            qqnorm           ranef           
## [33] recover_data     residuals        S                sigma           
## [37] simulate         summary          update           VarCorr         
## [41] Variogram        vcov            
## see &#39;?methods&#39; for accessing help and source code
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;methods(class = &amp;quot;merMod&amp;quot;) # for nlme objects 
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] anova            Anova            as.function      coef            
##  [5] confint          cooks.distance   deltaMethod      deviance        
##  [9] df.residual      drop1            emm_basis        extractAIC      
## [13] family           fitted           fixef            formula         
## [17] getData          getL             getME            hatvalues       
## [21] influence        isGLMM           isLMM            isNLMM          
## [25] isREML           linearHypothesis logLik           matchCoefs      
## [29] model.frame      model.matrix     na.action        ngrps           
## [33] nobs             plot             predict          print           
## [37] profile          ranef            recover_data     refit           
## [41] refitML          rePCA            residuals        rstudent        
## [45] show             sigma            simulate         summary         
## [49] terms            update           VarCorr          vcov            
## [53] vif              weights         
## see &#39;?methods&#39; for accessing help and source code
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The package &lt;strong&gt;emmeans&lt;/strong&gt; also supports &lt;a href=&#34;https://cran.r-project.org/web/packages/emmeans/vignettes/models.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;a large number of models&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slide set of spatial recipes</title>
      <link>/draft-workshops/spatial_workshop_new/slide-set/</link>
      <pubDate>Sun, 07 Nov 2021 09:00:00 +0000</pubDate>
      <guid>/draft-workshops/spatial_workshop_new/slide-set/</guid>
      <description>&lt;p&gt;Here is the slide set for the workshop. A more extensive resource is also available [here](Spatial Recipes for Field Trials).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Incorporating Spatial Covariates into Planned Field Experienments</title>
      <link>/project/spatial-stats-field-trials/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/project/spatial-stats-field-trials/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Getting R Set Up</title>
      <link>/post/getting-r-setup/</link>
      <pubDate>Thu, 15 Apr 2021 00:00:00 +0000</pubDate>
      <guid>/post/getting-r-setup/</guid>
      <description>&lt;h3 id=&#34;install-r&#34;&gt;Install R:&lt;/h3&gt;
&lt;p&gt;You can download R &lt;a href=&#34;https://cloud.r-project.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. Get the correct R distribution for your operating system. Once downloaded, click on downloaded file, and follow the installation instructions.&lt;/p&gt;
&lt;p&gt;Note that R is updated several times per year. If your installation is a year old or more, consider updating your version of R to the latest version.&lt;/p&gt;
&lt;h3 id=&#34;install-rstudio&#34;&gt;Install RStudio&lt;/h3&gt;
&lt;p&gt;Rstudio is not R, rather, it is a user interface for accessing R. It is a complicated interface with many features for developers. Despite its complexity, RStudio is nevertheless a very helpful R user interface for users of all abilities. It can downloaded &lt;a href=&#34;https://www.rstudio.com/products/rstudio/download/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. For most users, the free version of &amp;ldquo;RStudio Desktop&amp;rdquo; should be chosen. Once downloaded, click on downloaded file, and follow the installation instructions.&lt;/p&gt;
&lt;h3 id=&#34;install-rtools-optional&#34;&gt;Install Rtools (optional)&lt;/h3&gt;
&lt;p&gt;Only Windows users need to consider this step. This app is for compiling R packages with C, C++ and Fortran code. It is a separate piece of software that has to be downloaded and installed (it is not an R package). Rtools is not needed by all users and if you don&amp;rsquo;t know if you need this, it is absolutely fine to skip this step.  If you do think you need this, You can find it &lt;a href=&#34;https://cran.r-project.org/bin/windows/Rtools/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. Download and install.&lt;/p&gt;
&lt;h3 id=&#34;setting-up-rstudio-setup-optional&#34;&gt;Setting up RStudio Setup (optional)&lt;/h3&gt;
&lt;p&gt;This is an optional step, but it is highly recommended. This step will prevent RStudio from saving all of your objects in a session to &lt;em&gt;.Rdata&lt;/em&gt; file that is then automatically loaded whenever you open R.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;usethis&amp;quot;); library(usethis)
usethis::use_blank_slate()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can disable this across all projects in R with the drop-down menu &lt;strong&gt;Tools&lt;/strong&gt; &amp;ndash;&amp;gt; &lt;strong&gt;Global Options&amp;hellip;&lt;/strong&gt; &amp;ndash;&amp;gt; unclick &amp;lsquo;&lt;strong&gt;Restore .RData into workspace at startup&lt;/strong&gt;&amp;rsquo; and set &amp;lsquo;&lt;strong&gt;Save workspace to .rRData on exit&lt;/strong&gt;&amp;rsquo; to &amp;lsquo;&lt;strong&gt;Never&lt;/strong&gt;&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;Why is automatic loading of an &lt;em&gt;.Rdata&lt;/em&gt; file not recommended? Because it makes your work less reproducible. You may have created test objects that will unexpectedly interfere with downstream operations or analysis. You may have changed the original data source, but an older version is saved in the &lt;em&gt;.Rdata&lt;/em&gt; file. More explanation is given by &lt;a href=&#34;https://usethis.r-lib.org/reference/use_blank_slate.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RStudio&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are used to opening R and seeing all of your previous objects automatically loaded into the objects pane, this will be an adjustment. The solution is to save your processes into &lt;em&gt;.R&lt;/em&gt; scripts that capture all information from packages loaded, file import, all data manipulations and other operations important. If these steps are slow and there is a need to access intermediate objects, these can be saved in tabular formats readable by many applications (e.g. &lt;em&gt;.txt&lt;/em&gt; or &lt;em&gt;.csv&lt;/em&gt;) or saved as a specific R object (see &lt;code&gt;saveRDS()&lt;/code&gt; in the R help files) and reloaded in another session.&lt;/p&gt;
&lt;h4 id=&#34;set-up-version-control-optional&#34;&gt;Set up version control (optional)&lt;/h4&gt;
&lt;p&gt;If you use Git or SVN, you can perform Git operations directions from RStudio and interact with remote repositories. If you don&amp;rsquo;t use version control, this step can be skipped. If you do use version control, the command line or other third-party software (e.g. Gitkraken) are fine to use instead or in addition to RStudio&amp;rsquo;s interface. The implementation of git in R is very minimal and supports only a limited number of actions, so you are likely to need other software to perform complicated git actions. It is useful for file additions, commits, pushes and pulls.&lt;/p&gt;
&lt;p&gt;You can set up Git by going to &lt;strong&gt;Tools&lt;/strong&gt; &amp;ndash;&amp;gt; &lt;strong&gt;Global Options&lt;/strong&gt; &amp;ndash;&amp;gt; &lt;strong&gt;Git/SVN&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This is not the right space to provide detailed instructions for using git as an R user, but Jenny Bryan has written a very helpful &lt;a href=&#34;https://happygitwithr.com/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tutorial&lt;/a&gt; covering this subject.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Quick Tricks and Tips for Reproducible Research in R</title>
      <link>/post/reproducible-r/</link>
      <pubDate>Thu, 15 Apr 2021 00:00:00 +0000</pubDate>
      <guid>/post/reproducible-r/</guid>
      <description>&lt;h3 id=&#34;make-sure-your-rstudio-session-is-not-saving-rdata-automatically&#34;&gt;Make sure your Rstudio session is not saving .RData automatically:&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Note: this step requires the &amp;lsquo;usethis&amp;rsquo; package; please install this package if you do not already have it installed.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Step 1 is to disable automatic saving of your objects to a &lt;em&gt;.RDat&lt;/em&gt;a file. This file is automatically loaded when R restarts. Since we often create all sorts of miscellaneous objects during a session with a clear record of why, loading all objects without a clear sense of their provenance is often not reproducible by other.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;usethis::use_blank_slate()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can read more about this function in its &lt;a href=&#34;https://usethis%60.R%60-lib.org/reference/use_blank_slate.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can disable this across all projects in R with the drop-down menu &lt;strong&gt;Tools&lt;/strong&gt; &amp;ndash;&amp;gt; &lt;strong&gt;Global Options&amp;hellip;&lt;/strong&gt; &amp;ndash;&amp;gt; unclick &amp;lsquo;&lt;strong&gt;Restore .RData into workspace at startup&lt;/strong&gt;&amp;rsquo; and set &amp;lsquo;&lt;strong&gt;Save workspace to .rRData on exit&lt;/strong&gt;&amp;rsquo; to &amp;lsquo;&lt;strong&gt;Never&lt;/strong&gt;&amp;rsquo;.&lt;/p&gt;
&lt;h3 id=&#34;save-all-code-you-run-in-an-r-or-rmd-file&#34;&gt;Save all code you run in an &lt;em&gt;.R&lt;/em&gt; or &lt;em&gt;.Rmd&lt;/em&gt; file&lt;/h3&gt;
&lt;p&gt;This is your source code. It&amp;rsquo;s as real and as important as your input data. This file should capture a set of actions that can be repeated by another person (e.g. your PI, other colleagues yourself in the future) including packages loaded, files imported, all data manipulations and the outputs from these actions (e.g. visualisations, analytical outcomes). The idea is to capture your thought process and specific actions so this can be repeated in full. In most analyses, it is extremely likely* you will revisit a project and need to repeat what has already been done! Keeping a record of actions will save you considerable time because you will not have to attempt to recall and/or reconstruct exactly what you did in previous sessions.&lt;/p&gt;
&lt;p&gt;*This is &lt;em&gt;almost&lt;/em&gt; guaranteed to happen!&lt;/p&gt;
&lt;h3 id=&#34;regularly-restart-your-r-session&#34;&gt;Regularly restart your R session&lt;/h3&gt;
&lt;p&gt;Yes, that means wiping all the loaded packaged and objects from the session (if you followed the first recommendation in these instructions), but the upside is that your analysis are reproducible. This means future you can repeat those analyses and get the same results back you did earlier.&lt;/p&gt;
&lt;p&gt;You can restart R by manually closing and opening RStudio. You can also restart the R session with RStudio by navigating to the menu item &lt;strong&gt;Session&lt;/strong&gt; &amp;ndash;&amp;gt; &lt;strong&gt;Restart R&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;use-r-projects&#34;&gt;Use R projects&lt;/h3&gt;
&lt;p&gt;This is optional, but it will make your life easier. Whenever you start a new analytical endeavor in R, create an R project by navigating to &lt;strong&gt;File&lt;/strong&gt; &amp;ndash;&amp;gt; &lt;strong&gt;New Project&lt;/strong&gt; in RStudio. There are many options available for setting the [project directory (where the &lt;em&gt;.Rproj&lt;/em&gt; file lives), the type of project (e.g. R package, Shiny app or blank), and options to initialise a git repo. The simplest option is to choose &lt;strong&gt;New Project&lt;/strong&gt; (no special type) in a dedicated directory. The main advantage of projects is that by opening an &lt;em&gt;.Rproj&lt;/em&gt; file, the working directory is automatically set to that directory. If you are using a cloud solution for working across different computers or working with collaborators, this will make things easier because you can use relative paths for importing data and outputting files. There would be no more need for this at the top of your script:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;setwd(&amp;quot;specific/path/to/my/computer&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Additionally, for setting up gitbooks through &amp;lsquo;bookdown&amp;rsquo;, R packages, Shiny apps, and other complicated R endeavors, the automated set-up through R projects can be immensely helpful.  This is sometimes referred to as &amp;ldquo;project-oriented workflow.&amp;rdquo; In addition to using R projects with a dedicated directory for each research project, I also prefer to have a consistent directory structure for each project like this one:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;top-level-directory
│   README.md
│
└───data
│   │   file011.txt
│   │   file012.txt
│   │
│   └───spatial_files
│       │   file208.dbf
│       │   file208.shp
│       │   file208.shx
│   
└───scripts
│   │   eda.R
│   │   analysis.R
│   │   plots.R
│   │   final_report.Rmd
|
└───outputs
│   │   plot1.png
│   │   blups.csv
|
└───extra
    │   some_paper.pdf
    │   ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I put all raw data needed for analysis into the &amp;lsquo;data&amp;rsquo; directory, any and all programming scripts in the &amp;lsquo;scripts&amp;rsquo; directory, all outputs (plots, tables, intermediate data object) in the &amp;lsquo;outputs&amp;rsquo; directory and everything else ends up &amp;lsquo;extra&amp;rsquo;. Naturally, there are many different directory structures to use and this is just one example. Find something that works best for your needs!&lt;/p&gt;
&lt;h3 id=&#34;use-the-here-package&#34;&gt;Use the &amp;lsquo;here&amp;rsquo; package.&lt;/h3&gt;
&lt;p&gt;This is also optional. It works like R projects for setting the working directory. However, for an R project to work, you have to open the .Rproj file in RStudio. What if you or your collaborators prefer to open R files directly and start using those? Here will look for the next directory level which there is a .Rproj file and set the working directory there.&lt;/p&gt;
&lt;p&gt;If you want to import a file, &amp;ldquo;datafile.csv&amp;rdquo; that located in the data directory. Your .R script is actually located in the &amp;lsquo;scripts&amp;rsquo; directory. Normally, if you try to read that in, you need to specify the full path to &amp;ldquo;mydata.csv&amp;rdquo; or set the working directory and use a relative path. Again, these paths will not work if you switch computers or your collaborators are running these scripts on their own systems. This system gets even more complicated when working with an .Rmd file. Here&amp;rsquo;s an alternative approach that works the same across files and systems:&lt;/p&gt;
&lt;p&gt;First, make sure you have .Rproj file to define the top-level directory.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(here)
mydata &amp;lt;- read.csv(here(&amp;quot;data&amp;quot;, &amp;quot;datafile.csv&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This code will construct this path: &amp;ldquo;data/datafile.csv&amp;rdquo; and execute that command under the assumption that wherever that .rproj is located (going up one directory at a time until it finds it) is where the working directory is set. Putting &lt;code&gt;library(here)&lt;/code&gt; into every .R or .Rmd file in a project will resolve these issues.&lt;/p&gt;
&lt;h3 id=&#34;use-r-environments&#34;&gt;Use R environments.&lt;/h3&gt;
&lt;p&gt;Again: optional, but it will make your life easier.&lt;/p&gt;
&lt;p&gt;Often in academia, I might do an analysis, move on to something else and then have to return that analysis months or years later. I probably will have updated R and some or all of the packages used in that analysis. As a result of these updates, my original code may not work at all or may not do the intended actions. What I need are both the older version of R and the older packages. The package &amp;lsquo;renv&amp;rsquo; is a solution. It captures the versions of R and the loaded packages. It also builds a custom package library for your package (and caches this information across other projects using &lt;code&gt;renv&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Start here:
&lt;em&gt;(you need to also be using Rprojects since&lt;/em&gt; &lt;code&gt;renv&lt;/code&gt; &lt;em&gt;is searching for .Rproj file)&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(renv)
renv::init()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you have a mature project that&amp;rsquo;s not undergoing any further development at this time, this is all you need to do.&lt;/p&gt;
&lt;p&gt;If you continue to develop your project and install new packages, update your R environment like thus to ensure new or updated packaged are included:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;renv::snapshot()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you&amp;rsquo;re familiar with &lt;strong&gt;Packrat&lt;/strong&gt;, this is a replacement for that. This is particularly helpful for things that may have a long life span, like Shiny apps. The &lt;a href=&#34;https://rstudio.github.io/renv/articles/renv.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;renv package&lt;/a&gt; has extensive documentation worth reading.&lt;/p&gt;
&lt;h3 id=&#34;final-comments&#34;&gt;Final Comments&lt;/h3&gt;
&lt;p&gt;There are many more resources and recommendations for conducting reproducible research in R. There an entire &lt;a href=&#34;https://cran%60.R%60-project.org/web/views/ReproducibleResearch.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN task view&lt;/a&gt; devoted to this!
three-elk-FARM-2001&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible Research</title>
      <link>/project/reproducible-research/</link>
      <pubDate>Thu, 15 Apr 2021 00:00:00 +0000</pubDate>
      <guid>/project/reproducible-research/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Routine Incorporation of Spatial Covariates into Analysis of Planned Field Experiments</title>
      <link>/talks/spatial_seminar_20210409/</link>
      <pubDate>Fri, 09 Apr 2021 15:30:00 +0000</pubDate>
      <guid>/talks/spatial_seminar_20210409/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/admin/config.yml</guid>
      <description></description>
    </item>
    
    <item>
      <title>Routine incorporation of Spatial Covariates into Analysis of Planned Field Experiments</title>
      <link>/slides/spatial_seminar_20210409/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/slides/spatial_seminar_20210409/</guid>
      <description>&lt;style type=&#34;text/css&#34;&gt;
=

ul {
  color: #282828;
  font-size: 40px;
}

&lt;/style&gt;
&lt;h2 id=&#34;heading&#34;&gt;&lt;/h2&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;images/road-auvers-after-rain-6_2840.jpg&#34; alt=&#34;A Road in Auvers After the Rain by Vincent Van Gogh&#34; width=&#34;70%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;A Road in Auvers After the Rain by Vincent Van Gogh&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id=&#34;heading-1&#34;&gt;&lt;/h2&gt;
&lt;center&gt; 
### Goal: Make everyone feel more comfortable using spatial stats when analyzing field experimental data. 
&lt;p&gt;(you don&amp;rsquo;t have to be a geospatial statistics expert)&lt;/p&gt;
&lt;/center&gt;
&lt;h2 id=&#34;where-to-find-this-information&#34;&gt;Where to Find This Information&lt;/h2&gt;
&lt;p&gt;This Presentation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://github.com/IdahoAgStats/lattice-spatial-analysis-talk
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A longer tutorial:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://idahoagstats.github.io/guide-to-field-trial-spatial-analysis
&lt;/code&gt;&lt;/pre&gt;
&lt;need presentation url&gt;
&lt;h2 id=&#34;what-are-barriers-to-using-spatial-stats&#34;&gt;What Are Barriers to Using Spatial Stats?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Perceived lack of need&lt;/li&gt;
&lt;li&gt;Unsure of benefits&lt;/li&gt;
&lt;li&gt;No training in the topic/intimidated by the statistical methodology&lt;/li&gt;
&lt;li&gt;Limited time to devote to statistical analysis&lt;/li&gt;
&lt;li&gt;Unclear what would happen to blocking if spatial stats are used&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;very few resources for easy implementation&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spatial-variation-in-agricultural-fields&#34;&gt;Spatial Variation in Agricultural Fields&lt;/h2&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;images/Parker_farm.png&#34; alt=&#34;Univeristy of Idaho&#39;s Parker Farm (Moscow, Idaho)&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Univeristy of Idaho&#39;s Parker Farm (Moscow, Idaho)&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id=&#34;spatial-variation-in-agricultural-fields-1&#34;&gt;Spatial Variation in Agricultural Fields&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;blocking-in-agricultural-fields&#34;&gt;Blocking in Agricultural Fields&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;blocking-versus-spatial-analysis&#34;&gt;Blocking versus Spatial Analysis&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;images/boyfriend_meme.jpg&#34; width=&#34;60%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is not how this works. Blocking &lt;strong&gt;is&lt;/strong&gt; compatible with spatial analysis and recommended for most (all?) field trials.&lt;/p&gt;
&lt;h2 id=&#34;there-are-many-spatial-methods-available&#34;&gt;There Are Many Spatial Methods Available&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;areal data&lt;/th&gt;
&lt;th&gt;correlated error models&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;row and column trend&lt;/td&gt;
&lt;td&gt;exponential&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;nearest neighbor&lt;/td&gt;
&lt;td&gt;spherical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;separable ARxAR models&lt;/td&gt;
&lt;td&gt;Gaussian&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;spatial error model&lt;/td&gt;
&lt;td&gt;Matern&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;spatial lag model&lt;/td&gt;
&lt;td&gt;Cauchy&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ARIMA&lt;/td&gt;
&lt;td&gt;power&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;splines&lt;/td&gt;
&lt;td&gt;linear&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GAMs&lt;/td&gt;
&lt;td&gt;many more&amp;hellip;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;these-methods-work&#34;&gt;These Methods Work&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;images/gif/spatial_gif.gif&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;h2 class=&#34;columns-2&#34; id=&#34;these-methods-can-be-complex&#34;&gt;These Methods Can Be Complex  &lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;images/ikea.jpg&#34; width=&#34;80%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;hellip;.But&lt;/p&gt;
&lt;p&gt;You can also integrate spatial methods into gridded field trials without:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;having to know anything about map projections, shapefiles or other geospatial terminology&lt;/li&gt;
&lt;li&gt;possessing a deep understanding of linear modeling techniques or empirical variograms&lt;/li&gt;
&lt;li&gt;being an R or SAS programming expert&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Knowing these things is helpful, but not essential.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;a-typical-experiment&#34;&gt;A Typical Experiment&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Experimental treatments&lt;/li&gt;
&lt;li&gt;fully crossed effects&lt;/li&gt;
&lt;li&gt;Blocking scheme along the expected direction of field variation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-12-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;analysis&#34;&gt;Analysis&lt;/h2&gt;
&lt;h5 id=&#34;a-typical-linear-model&#34;&gt;A typical linear model:&lt;/h5&gt;
&lt;p&gt;$Y_{ij} = \mu + \alpha_i + \beta_j + \epsilon_{ij}$&lt;/p&gt;
&lt;p&gt;Response = trial mean + treatment effect + block effect + leftover error&lt;/p&gt;
&lt;h5 id=&#34;we-assume&#34;&gt;We Assume:&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;The error terms, or residuals, are independent of another with a shared distribution:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$\epsilon_i \sim  N(0,\sigma_e)$$&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Each block captures variation unique to that block and there is no other variation related to spatial position of the experimental plots.&lt;/li&gt;
&lt;/ol&gt;
&lt;center&gt; **How often is #2 evaluated?** &lt;/center&gt;
&lt;h2 id=&#34;example-analysis&#34;&gt;Example Analysis&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-13-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;average-yield-by-row-column-and-block&#34;&gt;Average Yield by Row, Column and Block&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;standard-analysis-of-kimberly-2013-wheat-variety-trial&#34;&gt;Standard Analysis of Kimberly, 2013 Wheat Variety Trial&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;36 soft white winter wheat cultivars&lt;/li&gt;
&lt;li&gt;4 blocks&lt;/li&gt;
&lt;li&gt;2 missing data points&lt;/li&gt;
&lt;li&gt;the linear model:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$Y_{ij} = \mu + \alpha_i + \beta_j + \epsilon_{ij}$&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(nlme)
lm1 &amp;lt;- lme(yield ~ cultivar, random = ~ 1|block, data = mydata, na.action = na.exclude)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;what-do-the-residuals-look-like&#34;&gt;What Do The Residuals Look Like?&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(lm1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-16-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-do-the-residuals-look-like-spatially&#34;&gt;What Do The Residuals Look Like Spatially?&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-18-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-do-the-residuals-look-like-spatially-1&#34;&gt;What Do The Residuals Look Like Spatially?&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-19-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;global-morans-test-for-spatial-autocorrelation&#34;&gt;Global Moran&amp;rsquo;s Test for Spatial Autocorrelation&lt;/h2&gt;
&lt;p&gt;$H_0$: There is no spatial autocorrelation &lt;br&gt;
$H_a:$  There is spatial autocorrelation!&lt;/p&gt;
&lt;p&gt;This uses a simple weighting matrix that weights all neighbors that share a plot border (the chess-based &amp;ldquo;rook&amp;rdquo; formation) equally.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
## 	Monte-Carlo simulation of Moran I
## 
## data:  mydata$residuals 
## weights: weights 
## omitted: 88, 97 
## number of simulations + 1: 1000 
## 
## statistic = 0.15869, observed rank = 997, p-value = 0.003
## alternative hypothesis: greater
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;handling-spatial-autocorrelation-in-areal-data&#34;&gt;Handling Spatial Autocorrelation in Areal Data&lt;/h2&gt;
&lt;p&gt;Areal data = finite region divided into discrete sub-regions (plots) with aggregated outcomes&lt;/p&gt;
&lt;p&gt;Options:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;model row and column trends
&lt;ul&gt;
&lt;li&gt;good for known gradients (hill slope, salinity patterns)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;assume plots close together are more similar than plots far apart. The errors terms can be modelled based on proximity, but there is no trial-wide trend
&lt;ul&gt;
&lt;li&gt;autoregressive models (AR)&lt;/li&gt;
&lt;li&gt;models utilizing &amp;ldquo;gaussian random fields&amp;rdquo; for continuously varying data (e.g. point data)&lt;/li&gt;
&lt;li&gt;Smoothing splines&lt;/li&gt;
&lt;li&gt;nearest neighbor&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;basic-linear-model&#34;&gt;Basic Linear Model&lt;/h2&gt;
&lt;p&gt;$$Y_{ij} = \mu + A_i + \epsilon_{ij}$$
$$\epsilon_i \sim  N(0,\sigma)$$&lt;/p&gt;
&lt;p&gt;If N = 4:&lt;/p&gt;
&lt;p&gt;$$e_i ~\sim N \Bigg( 0,
\left[ {\begin{array}{ccc} \sigma^2 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\
0 &amp;amp; \sigma^2 &amp;amp; 0 &amp;amp; 0\
0 &amp;amp; 0 &amp;amp; \sigma^2 &amp;amp; 0\&lt;br&gt;
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \sigma^2
\end{array}  } \right] \Bigg) $$&lt;/p&gt;
&lt;p&gt;The variance-covariance matrix indicates a shared variance and all off-diagonals are zero, that is, the errors are uncorrelated.&lt;/p&gt;
&lt;h2 id=&#34;linear-model-with-autoregressive-ar-errors&#34;&gt;Linear Model with Autoregressive (AR) Errors&lt;/h2&gt;
&lt;p&gt;Same linear model:
$$Y_{ij} = \mu + A_i + \epsilon_{ij}$$&lt;/p&gt;
&lt;p&gt;Different variance structure:&lt;/p&gt;
&lt;p&gt;$$e_i ~\sim N \Bigg( 0,  = \sigma^2
\left[ {\begin{array}{cc} 1 &amp;amp; \rho &amp;amp; \rho^2 &amp;amp; \rho^3 \&lt;br&gt;
\rho &amp;amp; 1 &amp;amp; \rho &amp;amp; \rho^2 \&lt;br&gt;
\rho^2 &amp;amp; \rho &amp;amp; 1 &amp;amp; \rho \&lt;br&gt;
\rho^3 &amp;amp; \rho^2 &amp;amp; \rho &amp;amp; 1 \
\end{array} } \right] \Bigg) $$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\rho$ is a correlation parameter ranging from -1 to 1 where 0 is no correlation and values approaching 1 indicate spatial correlation.&lt;/li&gt;
&lt;li&gt;The &amp;ldquo;one&amp;rdquo; in AR1 means that only the next most adjacent point is considered. There can be AR2, AR3, &amp;hellip;, ARn models.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class=&#34;columns-2&#34; id=&#34;the-separable-ar1-x-ar1-model&#34;&gt;The Separable AR1 x AR1 model &lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AR1xAR1 assumes correlation in two directions, row and column.&lt;/li&gt;
&lt;li&gt;It estimates $\sigma$, $\rho_{column}$, and $\rho_{row}$&lt;/li&gt;
&lt;li&gt;often a good choice since plot are rectangular and hence autocorrelation will differ by direction (&amp;ldquo;anistropy&amp;rdquo;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;more-notes-on-separable-ar1xar1&#34;&gt;More Notes on Separable AR1xAR1&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;From a statistical standpoint, it&amp;rsquo;s one of the more intuitive models&lt;/li&gt;
&lt;li&gt;The implementation in R is a little shaky
&lt;ul&gt;
&lt;li&gt;several packages, all hard to use and incompatible with other R packages&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;It is implemented in SAS&lt;/li&gt;
&lt;li&gt;Some proprietary software implements this (AsREML), others do not (Agrobase)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;semivariance-and-empirical-variograms&#34;&gt;Semivariance and Empirical Variograms&lt;/h2&gt;
&lt;p&gt;A measure of spatial correlation based on all pairwise correlations in a data set, binned by distance apart:&lt;/p&gt;
&lt;p&gt;$\gamma^2(h) = \frac{1}{2} Var[Z(s+h)-Z(s)]$&lt;br&gt;
$Z(s)$ = observed data at point $s$.&lt;br&gt;
$Z(s)$ = observed data at another point $h$ distance from point $s$.&lt;/p&gt;
&lt;p&gt;For a data set with $N$ observation, there are this many pairwise points:&lt;/p&gt;
&lt;p&gt;$\frac{N(N-1)}{2}$&lt;/p&gt;
&lt;h2 id=&#34;empirical-variogram&#34;&gt;Empirical Variogram&lt;/h2&gt;
&lt;p&gt;This uses semivariance to mathematically relate spatial correlations with distance&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/Sadoti2014_spherical.jpg&#34; width=&#34;70%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;range = distance up to which is there is spatial correlation
sill = uncorrelated variance of the variable of interest
nugget = measurement error, or short-distance spatial variance and other unaccounted for variance&lt;/p&gt;
&lt;h2 id=&#34;semivariance--empirical-variograms&#34;&gt;Semivariance &amp;amp; Empirical Variograms&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;There are many difference mathematical models for explaining semivariance:
&lt;ul&gt;
&lt;li&gt;exponential, Gaussian, Matérn, spherical, &amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;It is usually used for kriging, or prediction of a new point through spatial interpolation&lt;/li&gt;
&lt;li&gt;It can also be used in a linear model where local observations are used to predict a data point in addition to treatment effects&lt;/li&gt;
&lt;li&gt;Bonus: R and SAS are really good at this!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;adding-semivariance-to-a-linear-model&#34;&gt;Adding Semivariance to a Linear Model&lt;/h2&gt;
&lt;p&gt;Copy data into new object so we can assign it a new class (and remove missing data):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(gstat); library(sp); library(dplyr)
mydata_sp &amp;lt;- mydata %&amp;gt;% filter(!is.na(yield))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Establish &lt;code&gt;coordinates&lt;/code&gt; for data set to make it an &lt;code&gt;sp&lt;/code&gt; object (&amp;ldquo;spatial points&amp;rdquo;):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;coordinates(mydata_sp) &amp;lt;- ~ row + range
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Set the maximum distance for looking at pairwise correlations:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;max_dist &amp;lt;- 0.5*max(dist(coordinates(mydata_sp)))
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;adding-semivariance-to-a-linear-model-1&#34;&gt;Adding Semivariance to a Linear Model&lt;/h2&gt;
&lt;p&gt;Calculate a sample variogram:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;semivar &amp;lt;- variogram(yield ~ block + cultivar, data = mydata_sp,
                        cutoff = max_dist, width = max_dist/12)
nugget_start &amp;lt;- min(semivar$gamma)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;adding-semivariance-to-a-linear-model-2&#34;&gt;Adding Semivariance to a Linear Model&lt;/h2&gt;
&lt;p&gt;The empirical variogram:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(semivar)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-27-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;adding-semivariance-to-a-linear-model-3&#34;&gt;Adding Semivariance to a Linear Model&lt;/h2&gt;
&lt;p&gt;Set up models for fitting variograms:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;vgm1 &amp;lt;- vgm(model = &amp;quot;Exp&amp;quot;, nugget = nugget_start) # exponential
vgm2 &amp;lt;- vgm(model = &amp;quot;Sph&amp;quot;, nugget = nugget_start) # spherical
vgm3 &amp;lt;- vgm(model = &amp;quot;Gau&amp;quot;, nugget = nugget_start) # Gaussian
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fit the variogram models to the data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;variofit1 &amp;lt;- fit.variogram(semivar, vgm1)
variofit2 &amp;lt;- fit.variogram(semivar, vgm2)
variofit3 &amp;lt;- fit.variogram(semivar, vgm3)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;adding-semivariance-to-a-linear-model-4&#34;&gt;Adding Semivariance to a Linear Model&lt;/h2&gt;
&lt;p&gt;Look at the error terms to see which model is the best at minimizing error.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;exponential: 26857.3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;spherical: 26058.3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Gaussian: 41861.0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The spherical model is the best at minimizing error.&lt;/p&gt;
&lt;h2 id=&#34;adding-semivariance-to-a-linear-model-5&#34;&gt;Adding Semivariance to a Linear Model&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plot(semivar, variofit2, main = &amp;quot;Spherical model&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-31-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;adding-semivariance-to-a-linear-model-6&#34;&gt;Adding Semivariance to a Linear Model&lt;/h2&gt;
&lt;p&gt;Extract the nugget and sill information from the spherical variogram:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;nugget &amp;lt;- variofit2$psill[1] 
range &amp;lt;- variofit2$range[2] 
sill &amp;lt;- sum(variofit2$psill) 
nugget.effect &amp;lt;- nugget/sill  # the nugget/sill ratio
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;adding-semivariance-to-a-linear-model-7&#34;&gt;Adding Semivariance to a Linear Model&lt;/h2&gt;
&lt;p&gt;Build a correlation structure in &lt;code&gt;nlme&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor.sph &amp;lt;- corSpatial(value = c(range, nugget.effect), 
                  form = ~ row + range, 
                  nugget = T, fixed = F,
                  type = &amp;quot;spherical&amp;quot;, 
                  metric = &amp;quot;euclidean&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Update the Model:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;lm_sph &amp;lt;- update(lm1, corr = cor.sph)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;compare-models---log-likelihood&#34;&gt;Compare Models - Log likelihood&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;logLik(lm1)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &#39;log Lik.&#39; -489.0572 (df=38)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;logLik(lm_sph)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &#39;log Lik.&#39; -445.4782 (df=40)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;compare-models---post-hoc-power&#34;&gt;Compare Models - Post-hoc Power&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;anova(lm1)[2,]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          numDF denDF F-value p-value
## cultivar    35   103  1.6411   0.029
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;anova(lm_sph)[2,]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          numDF denDF  F-value p-value
## cultivar    35   103 2.054749  0.0028
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;compare-model-predictions&#34;&gt;Compare Model Predictions&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(emmeans)
lme_preds &amp;lt;- as.data.frame(emmeans(lm1, &amp;quot;cultivar&amp;quot;)) %&amp;gt;% mutate(model = &amp;quot;mixed model&amp;quot;)
sph_preds &amp;lt;- as.data.frame(emmeans(lm_sph, &amp;quot;cultivar&amp;quot;)) %&amp;gt;% 
  mutate(model = &amp;quot;mixed model + spatial&amp;quot;)
preds &amp;lt;- rbind(lme_preds, sph_preds)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;compare-model-predictions-1&#34;&gt;Compare Model Predictions&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-38-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Highest yielding wheat: &amp;lsquo;Stephens&amp;rsquo; (released in 1977)&lt;/p&gt;
&lt;h2 id=&#34;where-was-stephens-located-in-the-trial&#34;&gt;Where Was Stephens Located in the Trial?&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;main_presentation_files/figure-html/unnamed-chunk-40-1.png&#34; alt=&#34;&#34;&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;h2 id=&#34;more-notes&#34;&gt;More Notes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;When models omit blocking, the predictions may be unchanged or they may worsen. This varies by the agronomic field, but in general, blocking a field trial and including block in the statistical model improves your experimental power and controls experimental error.&lt;/li&gt;
&lt;li&gt;There is no single spatial model that fits all&lt;/li&gt;
&lt;li&gt;However, using any spatial model is usually better than none at all&lt;/li&gt;
&lt;li&gt;When you use spatial covariates, your estimates are better and more precise. This really does help you!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;whats-next&#34;&gt;What&amp;rsquo;s Next:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Track row and range information in your trial data set.&lt;/li&gt;
&lt;li&gt;Look at the tutorial! (we will also add SAS code)&lt;/li&gt;
&lt;li&gt;Try out a few models and see how it impacts your results.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;images/variety testing2.JPG&#34; width=&#34;60%&#34; /&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-seminar-was-brought-to-you-bystatistical-programs&#34;&gt;&lt;em&gt;The Seminar Was Brought to you by&amp;hellip;Statistical Programs!!!&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Statistical consulting to support the College of Agriculture and Life Sciences.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bill Price&lt;/strong&gt;, Director, &lt;a href=&#34;mailto:bprice@uidaho.edu&#34;&gt;bprice@uidaho.edu&lt;/a&gt;, AgSci307&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Julia Piaskowski&lt;/strong&gt;, &lt;a href=&#34;mailto:jpiaskowski@uidaho.edu&#34;&gt;jpiaskowski@uidaho.edu&lt;/a&gt;, AgSci 305&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
